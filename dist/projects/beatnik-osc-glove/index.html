<!DOCTYPE html><html lang="en" data-theme="light"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Beatnik — Gesture-Controlled OSC/MIDI Glove</title><link rel="stylesheet" href="../styles/global.css"></head> <body class="article-page"> <header class="top-header"> <div class="ribbon-nav"> <a href="/" class="ribbon-link ">RESUME</a> <span style="color:var(--card-border)">|</span> <a href="/projects/" class="ribbon-link active">PROJECTS</a> <span style="color:var(--card-border)">|</span> <a href="/mygpt/" class="ribbon-link ">GPT</a> </div> <button class="theme-switch" id="themeToggle" aria-label="Toggle theme">THEME</button> </header> <main>  <article class="article-shell"> <p class="article-meta" style="margin-top:0;">Prototype // Project Archive</p> <div class="article-body"> <h1 id="beatnik--gesture-controlled-oscmidi-glove">BEATNIK – Gesture-Controlled OSC/MIDI Glove</h1>
<hr>
<h2 id="1-overview">1. Overview</h2>
<p>BEATNIK is a wearable glove-based controller that converts gestures and finger movements into:</p>
<ul>
<li><strong>OSC (Open Sound Control) messages</strong>, and</li>
<li><strong>MIDI notes / MIDI Control Change messages</strong></li>
</ul>
<p>It enables expressive performance control for:</p>
<ul>
<li>synthesizers</li>
<li>DAWs (Ableton, Logic, FL Studio)</li>
<li>modular synthesis environments (Max/MSP, SuperCollider, Pure Data)</li>
<li>VST plugins and live performance rigs</li>
</ul>
<p>The system integrates:</p>
<ul>
<li>flex sensors</li>
<li>IMU/accelerometer</li>
<li>embedded C firmware</li>
<li>OSC/MIDI communication</li>
<li>host-side sound engines</li>
</ul>
<p>Its goal is to provide <strong>fluid, human, gestural music control</strong> that traditional knobs/sliders cannot offer.</p>
<hr>
<h2 id="2-problem-statement">2. Problem Statement</h2>
<p>Most music controllers:</p>
<ul>
<li>are discrete</li>
<li>rely on buttons/knobs</li>
<li>lack expressive nuance</li>
<li>feel mechanical rather rather than human</li>
</ul>
<p>BEATNIK enables <strong>natural, continuous, real-time control</strong> using gestures.</p>
<p>Challenges solved:</p>
<ul>
<li>stable sensor readings under noise</li>
<li>low-latency gesture detection</li>
<li>expressive mapping to MIDI/OSC</li>
<li>intuitive interface for performers</li>
</ul>
<hr>
<h2 id="3-system-architecture">3. System Architecture</h2>
<h3 id="hardware-layer"><strong>Hardware Layer</strong></h3>
<ul>
<li>Flex sensors (1 per finger)</li>
<li>IMU/accelerometer for tilt / roll / shake</li>
<li>Microcontroller (Arduino/Teensy class)</li>
</ul>
<h3 id="signal-processing-layer"><strong>Signal Processing Layer</strong></h3>
<ul>
<li>ADC sampling</li>
<li>Exponential smoothing to reduce jitter</li>
<li>Gesture classification</li>
<li>Noise thresholding</li>
</ul>
<h3 id="osc--midi-output-layer"><strong>OSC &#x26; MIDI Output Layer</strong></h3>
<ul>
<li>OSC message packer</li>
<li>MIDI note generator</li>
<li>MIDI CC mapping</li>
<li>Configurable output mode (OSC-only, MIDI-only, hybrid)</li>
</ul>
<h3 id="host-system"><strong>Host System</strong></h3>
<ul>
<li>DAW or synthesis environment that receives OSC or MIDI</li>
</ul>
<hr>
<h2 id="4-osc-messaging-full-technical-detail">4. OSC Messaging (Full Technical Detail)</h2>
<p>OSC messages follow a structured namespace:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>/beatnik/finger1      float 0.0–1.0</span></span>
<span class="line"><span>/beatnik/finger2      float 0.0–1.0</span></span>
<span class="line"><span>/beatnik/finger3      float 0.0–1.0</span></span>
<span class="line"><span>/beatnik/finger4      float 0.0–1.0</span></span>
<span class="line"><span>/beatnik/finger5      float 0.0–1.0</span></span>
<span class="line"><span></span></span>
<span class="line"><span>/beatnik/tilt         float -1.0–1.0</span></span>
<span class="line"><span>/beatnik/roll         float -1.0–1.0</span></span>
<span class="line"><span>/beatnik/shake        float 0–127</span></span>
<span class="line"><span></span></span></code></pre>
<h3 id="osc-uses">OSC Uses</h3>
<ul>
<li>Flex → filter cutoff, LFO depth, amplitude envelope</li>
<li>Tilt → pitch bend or spatialization</li>
<li>Shake → percussive trigger or FX burst</li>
</ul>
<h3 id="osc-rate">OSC Rate</h3>
<ul>
<li>Sent at <strong>30–60 Hz</strong> for smooth motion without overloading host apps</li>
</ul>
<hr>
<h2 id="5-midi-note--cc-messaging-full-detail">5. MIDI Note + CC Messaging (Full Detail)</h2>
<p>The glove supports three musical modes:</p>
<h3 id="a-midi-note-triggering"><strong>A) MIDI Note Triggering</strong></h3>
<p>Each finger can trigger notes:</p>






























<table><thead><tr><th>Finger Gesture</th><th>Threshold</th><th>MIDI Output</th></tr></thead><tbody><tr><td>Index bent</td><td>> bend_t</td><td>NOTE ON 60 velocity=X</td></tr><tr><td>Index released</td><td>&#x3C; bend_t</td><td>NOTE OFF 60</td></tr><tr><td>Middle bent</td><td>> bend_t</td><td>NOTE ON 62</td></tr><tr><td>Ring bent</td><td>…</td><td>NOTE ON 64</td></tr></tbody></table>
<h3 id="velocity-calculation"><strong>Velocity Calculation</strong></h3>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>velocity = clamp( (Δfinger_bend / Δt) * 127 )</span></span>
<span class="line"><span></span></span></code></pre>
<p>This creates <strong>human feel</strong> rather than fixed velocity.</p>
<hr>
<h3 id="b-midi-cc-control-continuous-control"><strong>B) MIDI CC Control (Continuous Control)</strong></h3>
<p>Recommended mappings:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>finger1 → CC74 (Filter Cutoff)</span></span>
<span class="line"><span>finger2 → CC1  (Mod Wheel / Vibrato)</span></span>
<span class="line"><span>finger3 → CC11 (Expression)</span></span>
<span class="line"><span>tilt    → CC10 (Pan)</span></span>
<span class="line"><span>shake   → CC5  (Portamento or FX depth)</span></span>
<span class="line"><span></span></span></code></pre>
<p>Gestures map to CC values <strong>0–127</strong>.</p>
<hr>
<h3 id="c-pitch-bend"><strong>C) Pitch Bend</strong></h3>
<p>Tilt angle → bend value:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>pitchbend = map(tilt, -1.0..1.0 → -8192..8191)</span></span>
<span class="line"><span></span></span></code></pre>
<hr>
<h3 id="supported-output-modes">Supported Output Modes</h3>





















<table><thead><tr><th>Mode</th><th>Behavior</th></tr></thead><tbody><tr><td>OSC-only</td><td>Continuous OSC messages only</td></tr><tr><td>MIDI-only</td><td>Notes + CC only</td></tr><tr><td>Hybrid</td><td>Sends both OSC + MIDI for experimental rigs</td></tr></tbody></table>
<hr>
<h2 id="6-implementation-details">6. Implementation Details</h2>
<h3 id="firmware-c">Firmware (C)</h3>
<ul>
<li>ADC sampling loop</li>
<li>Normalization of sensor values</li>
<li>Exponential smoothing filter</li>
<li>State machine for gesture detection</li>
<li>OSC packing (Lightweight OSC library)</li>
<li>MIDI over USB or serial</li>
</ul>
<h3 id="latency-optimization">Latency Optimization</h3>
<ul>
<li>Non-blocking timing loops</li>
<li>Minimal filtering delay (&#x3C;5 ms)</li>
<li>Efficient OSC batching</li>
<li>USB MIDI for ultra-low latency</li>
</ul>
<h3 id="host-setup">Host Setup</h3>
<p>Compatible with:</p>
<ul>
<li>Ableton Live (via virtual MIDI port or OSC bridge)</li>
<li>Max/MSP patches</li>
<li>SuperCollider SynthDefs</li>
<li>Logic Pro (MIDI layer)</li>
<li>Pure Data &#x26; VCV Rack (OSC)</li>
</ul>
<hr>
<h2 id="7-results">7. Results</h2>
<ul>
<li>Very expressive modulation (filter/fx sweeps)</li>
<li>Stable continuous CC values</li>
<li>Clean note triggering</li>
<li>&#x3C;20 ms total end-to-end latency</li>
<li>Natural gestural performance experience</li>
</ul>
<hr>
<h2 id="8-skills-demonstrated">8. Skills Demonstrated</h2>
<ul>
<li>Embedded C</li>
<li>Sensor fusion</li>
<li>Real-time filtering</li>
<li>OSC protocol implementation</li>
<li>MIDI generation</li>
<li>Human–computer interaction</li>
<li>Hardware–software integration</li>
</ul>
<hr>
<h2 id="9-narration--reflection">9. Narration / Reflection</h2>
<p>This project showed me how raw movement becomes <strong>musical performance</strong>.</p>
<p>I learned that:</p>
<ul>
<li>sensor data is noisy and must be shaped,</li>
<li>expressiveness requires continuous control,</li>
<li>OSC and MIDI each offer unique strengths,</li>
<li>real-time systems must feel responsive, not only correct.</li>
</ul>
<p>BEATNIK taught me to think from the <strong>performer’s perspective</strong>, not just the engineer’s.<br>
It shaped my sensitivity to latency, gesture dynamics, and expressive control — skills that later influenced
my DSP and audio engineering work.</p>
<hr> </div> </article>  </main> <script>
      const html = document.documentElement;
      const themes = ['light', 'dark'];
      (function initTheme() {
        let saved = localStorage.getItem('theme') || 'light';
        if (!themes.includes(saved)) saved = 'light';
        html.setAttribute('data-theme', saved);
        const next = themes[(themes.indexOf(saved) + 1) % themes.length];
        const btn = document.getElementById('themeToggle');
        if (btn) btn.innerText = next.toUpperCase();
      })();
      function toggleTheme() {
        const current = html.getAttribute('data-theme');
        const idx = themes.indexOf(current);
        const next = themes[(idx + 1) % themes.length];
        html.setAttribute('data-theme', next);
        const afterNext = themes[(idx + 2) % themes.length];
        const btn = document.getElementById('themeToggle');
        if (btn) btn.innerText = afterNext.toUpperCase();
        localStorage.setItem('theme', next);
      }
      const toggle = document.getElementById('themeToggle');
      if (toggle) toggle.addEventListener('click', toggleTheme);
    </script> </body> </html>