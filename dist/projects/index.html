<!DOCTYPE html><html lang="en" data-theme="light"> <head><meta charset="UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Wahaj Aslam | Projects</title><link rel="stylesheet" href="../styles/global.css"></head> <body class="projects-page"> <header class="top-header"> <div class="ribbon-nav"> <a href="/" class="ribbon-link ">RESUME</a> <span style="color:var(--card-border)">|</span> <a href="/projects/" class="ribbon-link active">PROJECTS</a> <span style="color:var(--card-border)">|</span> <a href="/mygpt/" class="ribbon-link ">GPT</a> </div> <button class="theme-switch" id="themeToggle" aria-label="Toggle theme">THEME</button> </header> <main>  <section id="archive"> <div class="section-header"> <span class="label">// PROJECTS</span> <div class="filter-controls"> <button class="filter-toggle-btn" id="filterToggle" aria-label="Open filters"> <span class="filter-icon">üîç</span> <span class="filter-label">SEARCH</span> <span class="filter-count" id="filterCount"></span> </button> </div> </div> <hr class="section-divider"> <div class="selected-tags-preview" id="selectedTagsPreview"></div> <div class="filter-panel" id="filterPanel" aria-hidden="true"> <div class="filter-panel-backdrop" id="filterPanelBackdrop"></div> <div class="filter-panel-content"> <div class="filter-panel-header"> <h3 class="filter-panel-title">FILTER PROJECTS</h3> <button class="filter-panel-close" id="filterPanelClose" aria-label="Close filters">√ó</button> </div> <div class="filter-search-wrapper"> <input type="text" class="filter-search-input" id="filterSearchInput" placeholder="Search tags..." autocomplete="off"> <span class="filter-search-icon">üîç</span> </div> <div class="filter-panel-body"> <div class="archive-filters" id="archiveFilters" aria-label="Filter projects by tag"></div> </div> </div> </div> <div class="archive-wrapper"> <div class="carousel-layout"> <button class="nav-btn prev" id="prevBtn" aria-label="Scroll Left">‚Üê</button> <div class="vhs-gallery" id="galleryContainer"> <div class="vhs-item" data-slug="arp_spoof_detector" data-title="Arp Spoof Detector" data-year="" data-format="" data-code="" data-desc="Python/Scapy ARP spoof detector with packet inspection, MAC/IP verification, and Wireshark-friendly logging." data-tags="network_security,arp_spoofing,intrusion_detection,packet_sniffing,python,scapy,wireshark,bash,networking,automation" data-image="" data-article="arp_spoof_detector"> <div class="vhs-spine-content"> <div class="vhs-code"></div> <div class="vhs-spine-text">Arp Spoof Detector</div> <div class="vhs-code"></div> <div class="vhs-play-icon" aria-hidden="true">‚ñ∂</div> </div> <div class="vhs-open-content"> <img src="" class="vhs-img-bg" alt="Cover"> <div class="vhs-info-layer"> <h3 class="vhs-title">Arp Spoof Detector</h3> <p class="vhs-desc">Python/Scapy ARP spoof detector with packet inspection, MAC/IP verification, and Wireshark-friendly logging.</p> <div class="vhs-tags"> <span class="vhs-tag">network_security</span><span class="vhs-tag">arp_spoofing</span><span class="vhs-tag">intrusion_detection</span><span class="vhs-tag">packet_sniffing</span><span class="vhs-tag">python</span><span class="vhs-tag">scapy</span><span class="vhs-tag">wireshark</span><span class="vhs-tag">bash</span><span class="vhs-tag">networking</span><span class="vhs-tag">automation</span> </div> </div> </div> </div><div class="vhs-item" data-slug="beatnik-osc-glove" data-title="Beatnik ‚Äî Gesture-Controlled OSC/MIDI Glove" data-year="Prototype" data-format="Project Archive" data-code="HCI-05" data-desc="Hand-gesture OSC glove with piezo/FSR sensing, active analog filtering, and DMA-driven MCU output. Interfaced with Ableton Live." data-tags="gesture_control,osc,midi,sensors,embedded,dma,piezo_sensing,stm32,c,ableton_live" data-image="https://images.unsplash.com/photo-1492684223066-81342ee5ff30?q=80&w=1000&auto=format&fit=crop" data-article="beatnik-osc-glove"> <div class="vhs-spine-content"> <div class="vhs-code">HCI-05</div> <div class="vhs-spine-text">Beatnik ‚Äî Gesture-Controlled OSC/MIDI Glove</div> <div class="vhs-code">Prototype</div> <div class="vhs-play-icon" aria-hidden="true">‚ñ∂</div> </div> <div class="vhs-open-content"> <img src="https://images.unsplash.com/photo-1492684223066-81342ee5ff30?q=80&w=1000&auto=format&fit=crop" class="vhs-img-bg" alt="Cover"> <div class="vhs-info-layer"> <h3 class="vhs-title">Beatnik ‚Äî Gesture-Controlled OSC/MIDI Glove</h3> <p class="vhs-desc">Hand-gesture OSC glove with piezo/FSR sensing, active analog filtering, and DMA-driven MCU output. Interfaced with Ableton Live.</p> <div class="vhs-tags"> <span class="vhs-tag">gesture_control</span><span class="vhs-tag">osc</span><span class="vhs-tag">midi</span><span class="vhs-tag">sensors</span><span class="vhs-tag">embedded</span><span class="vhs-tag">dma</span><span class="vhs-tag">piezo_sensing</span><span class="vhs-tag">stm32</span><span class="vhs-tag">c</span><span class="vhs-tag">ableton_live</span> </div> </div> </div> </div><div class="vhs-item" data-slug="dtmf_detector" data-title="DTMF Detector ‚Äî Goertzel-Based DSP Project" data-year="" data-format="" data-code="" data-desc="Goertzel-based DTMF detector on STM32/C with real-time tone validation, debouncing, and test coverage." data-tags="dsp,goertzel,dtmf,telephony,embedded,c,real_time,signal_processing,stm32,testing" data-image="" data-article="dtmf_detector"> <div class="vhs-spine-content"> <div class="vhs-code"></div> <div class="vhs-spine-text">DTMF Detector ‚Äî Goertzel-Based DSP Project</div> <div class="vhs-code"></div> <div class="vhs-play-icon" aria-hidden="true">‚ñ∂</div> </div> <div class="vhs-open-content"> <img src="" class="vhs-img-bg" alt="Cover"> <div class="vhs-info-layer"> <h3 class="vhs-title">DTMF Detector ‚Äî Goertzel-Based DSP Project</h3> <p class="vhs-desc">Goertzel-based DTMF detector on STM32/C with real-time tone validation, debouncing, and test coverage.</p> <div class="vhs-tags"> <span class="vhs-tag">dsp</span><span class="vhs-tag">goertzel</span><span class="vhs-tag">dtmf</span><span class="vhs-tag">telephony</span><span class="vhs-tag">embedded</span><span class="vhs-tag">c</span><span class="vhs-tag">real_time</span><span class="vhs-tag">signal_processing</span><span class="vhs-tag">stm32</span><span class="vhs-tag">testing</span> </div> </div> </div> </div><div class="vhs-item" data-slug="laser-harp" data-title="Laser Harp ‚Äî Optical Motion-Based Musical Instrument" data-year="Instrument" data-format="Project Archive" data-code="INS-06" data-desc="Laser-triggered MIDI controller using photodiodes and serial comms to drive performance hardware. Built on PIC Microcontroller." data-tags="laser,optics,embedded,sensors,musical_interface,midi,photodiodes,c,analog_filtering,calibration" data-image="https://images.unsplash.com/photo-1535905557558-afc4877a26fc?q=80&w=1000&auto=format&fit=crop" data-article="laser-harp"> <div class="vhs-spine-content"> <div class="vhs-code">INS-06</div> <div class="vhs-spine-text">Laser Harp ‚Äî Optical Motion-Based Musical Instrument</div> <div class="vhs-code">Instrument</div> <div class="vhs-play-icon" aria-hidden="true">‚ñ∂</div> </div> <div class="vhs-open-content"> <img src="https://images.unsplash.com/photo-1535905557558-afc4877a26fc?q=80&w=1000&auto=format&fit=crop" class="vhs-img-bg" alt="Cover"> <div class="vhs-info-layer"> <h3 class="vhs-title">Laser Harp ‚Äî Optical Motion-Based Musical Instrument</h3> <p class="vhs-desc">Laser-triggered MIDI controller using photodiodes and serial comms to drive performance hardware. Built on PIC Microcontroller.</p> <div class="vhs-tags"> <span class="vhs-tag">laser</span><span class="vhs-tag">optics</span><span class="vhs-tag">embedded</span><span class="vhs-tag">sensors</span><span class="vhs-tag">musical_interface</span><span class="vhs-tag">midi</span><span class="vhs-tag">photodiodes</span><span class="vhs-tag">c</span><span class="vhs-tag">analog_filtering</span><span class="vhs-tag">calibration</span> </div> </div> </div> </div><div class="vhs-item" data-slug="massive_mimo_seminar" data-title="Massive Mimo Seminar" data-year="" data-format="" data-code="" data-desc="Academic seminar on massive MU-MIMO downlink: linear precoding, beamforming pilots, achievable rates, and MATLAB simulations." data-tags="wireless,mimo,linear_precoding,sdr,beamforming,channel_modeling,matlab,mmwave,research,link_budget" data-image="" data-article="massive_mimo_seminar"> <div class="vhs-spine-content"> <div class="vhs-code"></div> <div class="vhs-spine-text">Massive Mimo Seminar</div> <div class="vhs-code"></div> <div class="vhs-play-icon" aria-hidden="true">‚ñ∂</div> </div> <div class="vhs-open-content"> <img src="" class="vhs-img-bg" alt="Cover"> <div class="vhs-info-layer"> <h3 class="vhs-title">Massive Mimo Seminar</h3> <p class="vhs-desc">Academic seminar on massive MU-MIMO downlink: linear precoding, beamforming pilots, achievable rates, and MATLAB simulations.</p> <div class="vhs-tags"> <span class="vhs-tag">wireless</span><span class="vhs-tag">mimo</span><span class="vhs-tag">linear_precoding</span><span class="vhs-tag">sdr</span><span class="vhs-tag">beamforming</span><span class="vhs-tag">channel_modeling</span><span class="vhs-tag">matlab</span><span class="vhs-tag">mmwave</span><span class="vhs-tag">research</span><span class="vhs-tag">link_budget</span> </div> </div> </div> </div><div class="vhs-item" data-slug="multihop_wireless_warp_prototyping" data-title="Multihop Wireless Warp Prototyping" data-year="" data-format="" data-code="" data-desc="WARP SDR multi-hop prototype with MATLAB tooling for packet tracing, channel modeling, and cooperative relay experiments." data-tags="wireless,sdr,matlab,multi_hop,cooperative_relays,ofdm,channel_modeling,warp,synchronization,link_budget" data-image="" data-article="multihop_wireless_warp_prototyping"> <div class="vhs-spine-content"> <div class="vhs-code"></div> <div class="vhs-spine-text">Multihop Wireless Warp Prototyping</div> <div class="vhs-code"></div> <div class="vhs-play-icon" aria-hidden="true">‚ñ∂</div> </div> <div class="vhs-open-content"> <img src="" class="vhs-img-bg" alt="Cover"> <div class="vhs-info-layer"> <h3 class="vhs-title">Multihop Wireless Warp Prototyping</h3> <p class="vhs-desc">WARP SDR multi-hop prototype with MATLAB tooling for packet tracing, channel modeling, and cooperative relay experiments.</p> <div class="vhs-tags"> <span class="vhs-tag">wireless</span><span class="vhs-tag">sdr</span><span class="vhs-tag">matlab</span><span class="vhs-tag">multi_hop</span><span class="vhs-tag">cooperative_relays</span><span class="vhs-tag">ofdm</span><span class="vhs-tag">channel_modeling</span><span class="vhs-tag">warp</span><span class="vhs-tag">synchronization</span><span class="vhs-tag">link_budget</span> </div> </div> </div> </div><div class="vhs-item" data-slug="my-live-portfolio" data-title="My Live Portfolio ‚Äî VHS" data-year="Personal System" data-format="Project Archive" data-code="VHS-09" data-desc="A living tape about why I turned my career into an adaptive portfolio instead of a flat PDF‚Äîhumorous, reflective, and stubbornly alive." data-tags="portfolio,web_design,javascript,css,html,accessibility,writing,branding,ai,storytelling" data-image="https://images.unsplash.com/photo-1516116216624-53e697fedbea?q=80&w=1000&auto=format&fit=crop" data-article="my-live-portfolio"> <div class="vhs-spine-content"> <div class="vhs-code">VHS-09</div> <div class="vhs-spine-text">My Live Portfolio ‚Äî VHS</div> <div class="vhs-code">Personal System</div> <div class="vhs-play-icon" aria-hidden="true">‚ñ∂</div> </div> <div class="vhs-open-content"> <img src="https://images.unsplash.com/photo-1516116216624-53e697fedbea?q=80&w=1000&auto=format&fit=crop" class="vhs-img-bg" alt="Cover"> <div class="vhs-info-layer"> <h3 class="vhs-title">My Live Portfolio ‚Äî VHS</h3> <p class="vhs-desc">A living tape about why I turned my career into an adaptive portfolio instead of a flat PDF‚Äîhumorous, reflective, and stubbornly alive.</p> <div class="vhs-tags"> <span class="vhs-tag">portfolio</span><span class="vhs-tag">web_design</span><span class="vhs-tag">javascript</span><span class="vhs-tag">css</span><span class="vhs-tag">html</span><span class="vhs-tag">accessibility</span><span class="vhs-tag">writing</span><span class="vhs-tag">branding</span><span class="vhs-tag">ai</span><span class="vhs-tag">storytelling</span> </div> </div> </div> </div><div class="vhs-item" data-slug="parallel-av-encoding-framework" data-title="Parallel A/V Encoding Framework" data-year="" data-format="" data-code="" data-desc="Concurrent FFmpeg + Python harness for ABR ladder experimentation with metrics and packaging." data-tags="ffmpeg,python,encoding,abr,metrics,bash,automation,packaging,streaming,monitoring" data-image="" data-article="parallel-av-encoding-framework"> <div class="vhs-spine-content"> <div class="vhs-code"></div> <div class="vhs-spine-text">Parallel A/V Encoding Framework</div> <div class="vhs-code"></div> <div class="vhs-play-icon" aria-hidden="true">‚ñ∂</div> </div> <div class="vhs-open-content"> <img src="" class="vhs-img-bg" alt="Cover"> <div class="vhs-info-layer"> <h3 class="vhs-title">Parallel A/V Encoding Framework</h3> <p class="vhs-desc">Concurrent FFmpeg + Python harness for ABR ladder experimentation with metrics and packaging.</p> <div class="vhs-tags"> <span class="vhs-tag">ffmpeg</span><span class="vhs-tag">python</span><span class="vhs-tag">encoding</span><span class="vhs-tag">abr</span><span class="vhs-tag">metrics</span><span class="vhs-tag">bash</span><span class="vhs-tag">automation</span><span class="vhs-tag">packaging</span><span class="vhs-tag">streaming</span><span class="vhs-tag">monitoring</span> </div> </div> </div> </div><div class="vhs-item" data-slug="parking_management_system" data-title="Parking Management System" data-year="" data-format="" data-code="" data-desc="Embedded parking system in C with sensor polling, UART/display updates, and real-time slot tracking." data-tags="embedded,sensors,microcontroller,parking_system,real_time,c,firmware,interrupts,uart,prototyping" data-image="" data-article="parking_management_system"> <div class="vhs-spine-content"> <div class="vhs-code"></div> <div class="vhs-spine-text">Parking Management System</div> <div class="vhs-code"></div> <div class="vhs-play-icon" aria-hidden="true">‚ñ∂</div> </div> <div class="vhs-open-content"> <img src="" class="vhs-img-bg" alt="Cover"> <div class="vhs-info-layer"> <h3 class="vhs-title">Parking Management System</h3> <p class="vhs-desc">Embedded parking system in C with sensor polling, UART/display updates, and real-time slot tracking.</p> <div class="vhs-tags"> <span class="vhs-tag">embedded</span><span class="vhs-tag">sensors</span><span class="vhs-tag">microcontroller</span><span class="vhs-tag">parking_system</span><span class="vhs-tag">real_time</span><span class="vhs-tag">c</span><span class="vhs-tag">firmware</span><span class="vhs-tag">interrupts</span><span class="vhs-tag">uart</span><span class="vhs-tag">prototyping</span> </div> </div> </div> </div><div class="vhs-item" data-slug="post-processing-separated-speech" data-title="Post-Processing Separated Speech" data-year="Master Thesis" data-format="Project Archive" data-code="DSP-01" data-desc="Reconstructed damaged time-frequency components of separated speech using bandwidth extension. Analyzed LPC Analysis/Synthesis, STFT &#38; Pitch Estimation, and Pole/Zero LPC Envelopes." data-tags="speech,dsp,bandwidth_extension,lpc,excitation,speech_enhancement,stft,python,matlab,research" data-image="https://images.unsplash.com/photo-1518770660439-4636190af475?q=80&w=1000&auto=format&fit=crop" data-article="post-processing-separated-speech"> <div class="vhs-spine-content"> <div class="vhs-code">DSP-01</div> <div class="vhs-spine-text">Post-Processing Separated Speech</div> <div class="vhs-code">Master Thesis</div> <div class="vhs-play-icon" aria-hidden="true">‚ñ∂</div> </div> <div class="vhs-open-content"> <img src="https://images.unsplash.com/photo-1518770660439-4636190af475?q=80&w=1000&auto=format&fit=crop" class="vhs-img-bg" alt="Cover"> <div class="vhs-info-layer"> <h3 class="vhs-title">Post-Processing Separated Speech</h3> <p class="vhs-desc">Reconstructed damaged time-frequency components of separated speech using bandwidth extension. Analyzed LPC Analysis/Synthesis, STFT &amp; Pitch Estimation, and Pole/Zero LPC Envelopes.</p> <div class="vhs-tags"> <span class="vhs-tag">speech</span><span class="vhs-tag">dsp</span><span class="vhs-tag">bandwidth_extension</span><span class="vhs-tag">lpc</span><span class="vhs-tag">excitation</span><span class="vhs-tag">speech_enhancement</span><span class="vhs-tag">stft</span><span class="vhs-tag">python</span><span class="vhs-tag">matlab</span><span class="vhs-tag">research</span> </div> </div> </div> </div><div class="vhs-item" data-slug="traffic_signal_controller" data-title="Traffic Signal Controller" data-year="" data-format="" data-code="" data-desc="Finite-state traffic light controller in C using timers/interrupts for deterministic, safe signal sequencing." data-tags="embedded,microcontroller,state_machine,real_time,c,timers,interrupts,firmware,prototyping,testing" data-image="" data-article="traffic_signal_controller"> <div class="vhs-spine-content"> <div class="vhs-code"></div> <div class="vhs-spine-text">Traffic Signal Controller</div> <div class="vhs-code"></div> <div class="vhs-play-icon" aria-hidden="true">‚ñ∂</div> </div> <div class="vhs-open-content"> <img src="" class="vhs-img-bg" alt="Cover"> <div class="vhs-info-layer"> <h3 class="vhs-title">Traffic Signal Controller</h3> <p class="vhs-desc">Finite-state traffic light controller in C using timers/interrupts for deterministic, safe signal sequencing.</p> <div class="vhs-tags"> <span class="vhs-tag">embedded</span><span class="vhs-tag">microcontroller</span><span class="vhs-tag">state_machine</span><span class="vhs-tag">real_time</span><span class="vhs-tag">c</span><span class="vhs-tag">timers</span><span class="vhs-tag">interrupts</span><span class="vhs-tag">firmware</span><span class="vhs-tag">prototyping</span><span class="vhs-tag">testing</span> </div> </div> </div> </div><div class="vhs-item" data-slug="vidi" data-title="Vidi ‚Äî Low-Latency Pitch Tool" data-year="Audio Tool" data-format="Project Archive" data-code="APP-03" data-desc="Pitch detection and shifting across parametric and non-parametric methods. Built with iOS Core Audio, vDSP/Accelerate, and MIDI Mapping." data-tags="audio,speech,dsp,pitch,core_audio,vDSP,ios,swift,midi,latency_optimization" data-image="https://images.unsplash.com/photo-1485846234645-a62644f84728?q=80&w=1000&auto=format&fit=crop" data-article="vidi"> <div class="vhs-spine-content"> <div class="vhs-code">APP-03</div> <div class="vhs-spine-text">Vidi ‚Äî Low-Latency Pitch Tool</div> <div class="vhs-code">Audio Tool</div> <div class="vhs-play-icon" aria-hidden="true">‚ñ∂</div> </div> <div class="vhs-open-content"> <img src="https://images.unsplash.com/photo-1485846234645-a62644f84728?q=80&w=1000&auto=format&fit=crop" class="vhs-img-bg" alt="Cover"> <div class="vhs-info-layer"> <h3 class="vhs-title">Vidi ‚Äî Low-Latency Pitch Tool</h3> <p class="vhs-desc">Pitch detection and shifting across parametric and non-parametric methods. Built with iOS Core Audio, vDSP/Accelerate, and MIDI Mapping.</p> <div class="vhs-tags"> <span class="vhs-tag">audio</span><span class="vhs-tag">speech</span><span class="vhs-tag">dsp</span><span class="vhs-tag">pitch</span><span class="vhs-tag">core_audio</span><span class="vhs-tag">vDSP</span><span class="vhs-tag">ios</span><span class="vhs-tag">swift</span><span class="vhs-tag">midi</span><span class="vhs-tag">latency_optimization</span> </div> </div> </div> </div> </div> <button class="nav-btn next" id="nextBtn" aria-label="Scroll Right">‚Üí</button> </div> </div> <div class="details-section blur-fade active"> <div class="details-meta"> <span class="label">CURRENT SELECTION</span> <h2 id="detailTitle" class="edu-degree mask-reveal active"><span>Select a Title</span></h2> <p id="detailYear">--</p> <p id="detailSummary" class="detail-summary">Select a tape to view its summary.</p> <div id="detailTags" class="detail-tags"></div> <div id="detailToc" class="detail-toc"></div> </div> <div class="details-body"> <p id="detailDesc">Browse the archive above. Click a tape to load details from the vault.</p> <div id="detailContent" class="detail-article"></div> <div id="detailActions" class="detail-actions"></div> </div> </div> <div id="projectContentStore" style="display:none"> <div id="project-content-arp_spoof_detector" data-slug="arp_spoof_detector"> <h1 id="arp-spoof-detector--python-based-network-security-tool">ARP Spoof Detector ‚Äî Python-Based Network Security Tool</h1>
<hr>
<h2 id="1-overview">1. Overview</h2>
<p>The <strong>ARP Spoof Detector</strong> is a Python-based defensive security tool that monitors a local network for
<strong>ARP poisoning</strong> attacks. ARP spoofing is a common technique used to:</p>
<ul>
<li>intercept traffic (Man-in-the-Middle attacks)</li>
<li>disrupt network connectivity</li>
<li>impersonate gateway or device IPs</li>
</ul>
<p>This tool continuously scans ARP packets, identifies suspicious MAC/IP mismatches, and alerts the user
in real time.</p>
<p>It demonstrates:</p>
<ul>
<li>network traffic analysis</li>
<li>ARP protocol understanding</li>
<li>attack detection logic</li>
<li>practical cybersecurity engineering</li>
</ul>
<hr>
<h2 id="2-problem-statement">2. Problem Statement</h2>
<p>In ARP spoofing:</p>
<ul>
<li>an attacker sends false ARP replies</li>
<li>associates their MAC with a victim‚Äôs IP address</li>
<li>reroutes or intercepts traffic</li>
</ul>
<p>Most devices never verify ARP messages, making the LAN vulnerable.</p>
<p>The goal of this project:</p>
<ul>
<li>detect ARP spoof events quickly</li>
<li>verify MAC/IP relationships</li>
<li>warn the user immediately</li>
<li>run efficiently on typical local networks</li>
</ul>
<hr>
<h2 id="3-system-architecture">3. System Architecture</h2>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>Network Traffic ‚Üí Packet Sniffer ‚Üí ARP Analyzer ‚Üí MAC Verification ‚Üí Alert System</span></span>
<span class="line"><span></span></span></code></pre>
<h3 id="components">Components</h3>
<ol>
<li>
<p><strong>Packet Sniffer</strong></p>
<ul>
<li>Uses <code>scapy</code> in Python</li>
<li>Listens for ARP ‚Äúwho-has‚Äù and ‚Äúis-at‚Äù packets</li>
</ul>
</li>
<li>
<p><strong>MAC Verification Engine</strong></p>
<ul>
<li>Maintains a trusted MAC‚ÄìIP mapping table</li>
<li>Detects changes or inconsistencies</li>
</ul>
</li>
<li>
<p><strong>Spoof Detection Logic</strong></p>
<ul>
<li>Identifies if two different MAC addresses claim the same IP</li>
<li>Flags if gateway IP is claimed by a non-gateway MAC</li>
</ul>
</li>
<li>
<p><strong>Alert System</strong></p>
<ul>
<li>Console warnings</li>
<li>Optional logging</li>
<li>Optional email/SMS alerts (extensible)</li>
</ul>
</li>
</ol>
<hr>
<h2 id="4-implementation-details">4. Implementation Details</h2>
<h3 id="41-packet-sniffing">4.1 Packet Sniffing</h3>
<p>Using Scapy:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">from</span><span style="color:#E1E4E8"> scapy.all </span><span style="color:#F97583">import</span><span style="color:#E1E4E8"> sniff, </span><span style="color:#79B8FF">ARP</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583">def</span><span style="color:#B392F0"> sniff_packets</span><span style="color:#E1E4E8">():</span></span>
<span class="line"><span style="color:#E1E4E8">    sniff(</span><span style="color:#FFAB70">store</span><span style="color:#F97583">=</span><span style="color:#79B8FF">False</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">prn</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">analyze_packet, </span><span style="color:#FFAB70">filter</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"arp"</span><span style="color:#E1E4E8">)</span></span>
<span class="line"></span></code></pre>
<h3 id="42-arp-analysis-logic">4.2 ARP Analysis Logic</h3>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">def</span><span style="color:#B392F0"> analyze_packet</span><span style="color:#E1E4E8">(pkt):</span></span>
<span class="line"><span style="color:#F97583">    if</span><span style="color:#E1E4E8"> pkt.haslayer(</span><span style="color:#79B8FF">ARP</span><span style="color:#E1E4E8">) </span><span style="color:#F97583">and</span><span style="color:#E1E4E8"> pkt[</span><span style="color:#79B8FF">ARP</span><span style="color:#E1E4E8">].op </span><span style="color:#F97583">==</span><span style="color:#79B8FF"> 2</span><span style="color:#E1E4E8">:  </span><span style="color:#6A737D"># ARP Reply</span></span>
<span class="line"><span style="color:#E1E4E8">        ip </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> pkt[</span><span style="color:#79B8FF">ARP</span><span style="color:#E1E4E8">].psrc</span></span>
<span class="line"><span style="color:#E1E4E8">        mac </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> pkt[</span><span style="color:#79B8FF">ARP</span><span style="color:#E1E4E8">].hwsrc</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583">        if</span><span style="color:#E1E4E8"> ip </span><span style="color:#F97583">in</span><span style="color:#E1E4E8"> ip_mac_table </span><span style="color:#F97583">and</span><span style="color:#E1E4E8"> ip_mac_table[ip] </span><span style="color:#F97583">!=</span><span style="color:#E1E4E8"> mac:</span></span>
<span class="line"><span style="color:#E1E4E8">            alert(ip, ip_mac_table[ip], mac)</span></span>
<span class="line"><span style="color:#F97583">        else</span><span style="color:#E1E4E8">:</span></span>
<span class="line"><span style="color:#E1E4E8">            ip_mac_table[ip] </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> mac</span></span>
<span class="line"></span></code></pre>
<h3 id="43-spoof-detection-conditions">4.3 Spoof Detection Conditions</h3>
<ul>
<li><strong>Condition A:</strong> Same IP seen with two different MACs</li>
<li><strong>Condition B:</strong> Gateway IP claimed by an unknown MAC</li>
<li><strong>Condition C:</strong> MAC address appears on sudden multiple IPs</li>
</ul>
<h3 id="44-alert-function">4.4 Alert Function</h3>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">def</span><span style="color:#B392F0"> alert</span><span style="color:#E1E4E8">(ip, original_mac, spoofed_mac):</span></span>
<span class="line"><span style="color:#79B8FF">    print</span><span style="color:#E1E4E8">(</span><span style="color:#F97583">f</span><span style="color:#9ECBFF">"[!] Possible ARP Spoof Detected:"</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#79B8FF">    print</span><span style="color:#E1E4E8">(</span><span style="color:#F97583">f</span><span style="color:#9ECBFF">"    IP Address: </span><span style="color:#79B8FF">{</span><span style="color:#E1E4E8">ip</span><span style="color:#79B8FF">}</span><span style="color:#9ECBFF">"</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#79B8FF">    print</span><span style="color:#E1E4E8">(</span><span style="color:#F97583">f</span><span style="color:#9ECBFF">"    Original MAC: </span><span style="color:#79B8FF">{</span><span style="color:#E1E4E8">original_mac</span><span style="color:#79B8FF">}</span><span style="color:#9ECBFF">"</span><span style="color:#E1E4E8">)</span></span>
<span class="line"><span style="color:#79B8FF">    print</span><span style="color:#E1E4E8">(</span><span style="color:#F97583">f</span><span style="color:#9ECBFF">"    Detected MAC: </span><span style="color:#79B8FF">{</span><span style="color:#E1E4E8">spoofed_mac</span><span style="color:#79B8FF">}</span><span style="color:#9ECBFF">"</span><span style="color:#E1E4E8">)</span></span>
<span class="line"></span></code></pre>
<h3 id="45-performance-considerations">4.5 Performance Considerations</h3>
<ul>
<li>Real-time detection with low CPU usage</li>
<li>Works on Wi-Fi and Ethernet</li>
<li>No need for packet storage ‚Üí memory efficient</li>
</ul>
<hr>
<h2 id="5-results">5. Results</h2>
<ul>
<li>Successfully detects ARP spoof attempts in real networks</li>
<li>Works immediately on common networks without special setup</li>
<li>Detects gateway spoofing (most dangerous case)</li>
<li>Minimal system resource usage</li>
<li>Easy to extend into a full IDS module</li>
</ul>
<hr>
<h2 id="6-skills-demonstrated">6. Skills Demonstrated</h2>
<ul>
<li>Python networking</li>
<li>Packet sniffing using Scapy</li>
<li>Understanding ARP protocol internals</li>
<li>Intrusion detection logic</li>
<li>Pattern recognition for MAC/IP inconsistencies</li>
<li>Practical cybersecurity tooling</li>
</ul>
<hr>
<h2 id="7-narration--reflection">7. Narration / Reflection</h2>
<p>Building this tool gave me hands-on insight into how simple but dangerous ARP spoofing is on typical
networks. It reinforced:</p>
<ul>
<li>the importance of validating assumptions in protocols</li>
<li>how fragile local network trust systems can be</li>
<li>how lightweight detection can significantly improve security</li>
</ul>
<p>This project strengthened my ability to think like both an attacker <strong>and</strong> a defender ‚Äî a skill that later
helped in debugging complex system interactions across networking, DSP, and embedded domains.</p>
<hr> </div><div id="project-content-beatnik-osc-glove" data-slug="beatnik-osc-glove"> <h1 id="beatnik--gesture-controlled-oscmidi-glove">BEATNIK ‚Äì Gesture-Controlled OSC/MIDI Glove</h1>
<hr>
<h2 id="1-overview">1. Overview</h2>
<p>BEATNIK is a wearable glove-based controller that converts gestures and finger movements into:</p>
<ul>
<li><strong>OSC (Open Sound Control) messages</strong>, and</li>
<li><strong>MIDI notes / MIDI Control Change messages</strong></li>
</ul>
<p>It enables expressive performance control for:</p>
<ul>
<li>synthesizers</li>
<li>DAWs (Ableton, Logic, FL Studio)</li>
<li>modular synthesis environments (Max/MSP, SuperCollider, Pure Data)</li>
<li>VST plugins and live performance rigs</li>
</ul>
<p>The system integrates:</p>
<ul>
<li>flex sensors</li>
<li>IMU/accelerometer</li>
<li>embedded C firmware</li>
<li>OSC/MIDI communication</li>
<li>host-side sound engines</li>
</ul>
<p>Its goal is to provide <strong>fluid, human, gestural music control</strong> that traditional knobs/sliders cannot offer.</p>
<hr>
<h2 id="2-problem-statement">2. Problem Statement</h2>
<p>Most music controllers:</p>
<ul>
<li>are discrete</li>
<li>rely on buttons/knobs</li>
<li>lack expressive nuance</li>
<li>feel mechanical rather rather than human</li>
</ul>
<p>BEATNIK enables <strong>natural, continuous, real-time control</strong> using gestures.</p>
<p>Challenges solved:</p>
<ul>
<li>stable sensor readings under noise</li>
<li>low-latency gesture detection</li>
<li>expressive mapping to MIDI/OSC</li>
<li>intuitive interface for performers</li>
</ul>
<hr>
<h2 id="3-system-architecture">3. System Architecture</h2>
<h3 id="hardware-layer"><strong>Hardware Layer</strong></h3>
<ul>
<li>Flex sensors (1 per finger)</li>
<li>IMU/accelerometer for tilt / roll / shake</li>
<li>Microcontroller (Arduino/Teensy class)</li>
</ul>
<h3 id="signal-processing-layer"><strong>Signal Processing Layer</strong></h3>
<ul>
<li>ADC sampling</li>
<li>Exponential smoothing to reduce jitter</li>
<li>Gesture classification</li>
<li>Noise thresholding</li>
</ul>
<h3 id="osc--midi-output-layer"><strong>OSC &#x26; MIDI Output Layer</strong></h3>
<ul>
<li>OSC message packer</li>
<li>MIDI note generator</li>
<li>MIDI CC mapping</li>
<li>Configurable output mode (OSC-only, MIDI-only, hybrid)</li>
</ul>
<h3 id="host-system"><strong>Host System</strong></h3>
<ul>
<li>DAW or synthesis environment that receives OSC or MIDI</li>
</ul>
<hr>
<h2 id="4-osc-messaging-full-technical-detail">4. OSC Messaging (Full Technical Detail)</h2>
<p>OSC messages follow a structured namespace:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>/beatnik/finger1      float 0.0‚Äì1.0</span></span>
<span class="line"><span>/beatnik/finger2      float 0.0‚Äì1.0</span></span>
<span class="line"><span>/beatnik/finger3      float 0.0‚Äì1.0</span></span>
<span class="line"><span>/beatnik/finger4      float 0.0‚Äì1.0</span></span>
<span class="line"><span>/beatnik/finger5      float 0.0‚Äì1.0</span></span>
<span class="line"><span></span></span>
<span class="line"><span>/beatnik/tilt         float -1.0‚Äì1.0</span></span>
<span class="line"><span>/beatnik/roll         float -1.0‚Äì1.0</span></span>
<span class="line"><span>/beatnik/shake        float 0‚Äì127</span></span>
<span class="line"><span></span></span></code></pre>
<h3 id="osc-uses">OSC Uses</h3>
<ul>
<li>Flex ‚Üí filter cutoff, LFO depth, amplitude envelope</li>
<li>Tilt ‚Üí pitch bend or spatialization</li>
<li>Shake ‚Üí percussive trigger or FX burst</li>
</ul>
<h3 id="osc-rate">OSC Rate</h3>
<ul>
<li>Sent at <strong>30‚Äì60 Hz</strong> for smooth motion without overloading host apps</li>
</ul>
<hr>
<h2 id="5-midi-note--cc-messaging-full-detail">5. MIDI Note + CC Messaging (Full Detail)</h2>
<p>The glove supports three musical modes:</p>
<h3 id="a-midi-note-triggering"><strong>A) MIDI Note Triggering</strong></h3>
<p>Each finger can trigger notes:</p>






























<table><thead><tr><th>Finger Gesture</th><th>Threshold</th><th>MIDI Output</th></tr></thead><tbody><tr><td>Index bent</td><td>> bend_t</td><td>NOTE ON 60 velocity=X</td></tr><tr><td>Index released</td><td>&#x3C; bend_t</td><td>NOTE OFF 60</td></tr><tr><td>Middle bent</td><td>> bend_t</td><td>NOTE ON 62</td></tr><tr><td>Ring bent</td><td>‚Ä¶</td><td>NOTE ON 64</td></tr></tbody></table>
<h3 id="velocity-calculation"><strong>Velocity Calculation</strong></h3>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>velocity = clamp( (Œîfinger_bend / Œît) * 127 )</span></span>
<span class="line"><span></span></span></code></pre>
<p>This creates <strong>human feel</strong> rather than fixed velocity.</p>
<hr>
<h3 id="b-midi-cc-control-continuous-control"><strong>B) MIDI CC Control (Continuous Control)</strong></h3>
<p>Recommended mappings:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>finger1 ‚Üí CC74 (Filter Cutoff)</span></span>
<span class="line"><span>finger2 ‚Üí CC1  (Mod Wheel / Vibrato)</span></span>
<span class="line"><span>finger3 ‚Üí CC11 (Expression)</span></span>
<span class="line"><span>tilt    ‚Üí CC10 (Pan)</span></span>
<span class="line"><span>shake   ‚Üí CC5  (Portamento or FX depth)</span></span>
<span class="line"><span></span></span></code></pre>
<p>Gestures map to CC values <strong>0‚Äì127</strong>.</p>
<hr>
<h3 id="c-pitch-bend"><strong>C) Pitch Bend</strong></h3>
<p>Tilt angle ‚Üí bend value:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>pitchbend = map(tilt, -1.0..1.0 ‚Üí -8192..8191)</span></span>
<span class="line"><span></span></span></code></pre>
<hr>
<h3 id="supported-output-modes">Supported Output Modes</h3>





















<table><thead><tr><th>Mode</th><th>Behavior</th></tr></thead><tbody><tr><td>OSC-only</td><td>Continuous OSC messages only</td></tr><tr><td>MIDI-only</td><td>Notes + CC only</td></tr><tr><td>Hybrid</td><td>Sends both OSC + MIDI for experimental rigs</td></tr></tbody></table>
<hr>
<h2 id="6-implementation-details">6. Implementation Details</h2>
<h3 id="firmware-c">Firmware (C)</h3>
<ul>
<li>ADC sampling loop</li>
<li>Normalization of sensor values</li>
<li>Exponential smoothing filter</li>
<li>State machine for gesture detection</li>
<li>OSC packing (Lightweight OSC library)</li>
<li>MIDI over USB or serial</li>
</ul>
<h3 id="latency-optimization">Latency Optimization</h3>
<ul>
<li>Non-blocking timing loops</li>
<li>Minimal filtering delay (&#x3C;5 ms)</li>
<li>Efficient OSC batching</li>
<li>USB MIDI for ultra-low latency</li>
</ul>
<h3 id="host-setup">Host Setup</h3>
<p>Compatible with:</p>
<ul>
<li>Ableton Live (via virtual MIDI port or OSC bridge)</li>
<li>Max/MSP patches</li>
<li>SuperCollider SynthDefs</li>
<li>Logic Pro (MIDI layer)</li>
<li>Pure Data &#x26; VCV Rack (OSC)</li>
</ul>
<hr>
<h2 id="7-results">7. Results</h2>
<ul>
<li>Very expressive modulation (filter/fx sweeps)</li>
<li>Stable continuous CC values</li>
<li>Clean note triggering</li>
<li>&#x3C;20 ms total end-to-end latency</li>
<li>Natural gestural performance experience</li>
</ul>
<hr>
<h2 id="8-skills-demonstrated">8. Skills Demonstrated</h2>
<ul>
<li>Embedded C</li>
<li>Sensor fusion</li>
<li>Real-time filtering</li>
<li>OSC protocol implementation</li>
<li>MIDI generation</li>
<li>Human‚Äìcomputer interaction</li>
<li>Hardware‚Äìsoftware integration</li>
</ul>
<hr>
<h2 id="9-narration--reflection">9. Narration / Reflection</h2>
<p>This project showed me how raw movement becomes <strong>musical performance</strong>.</p>
<p>I learned that:</p>
<ul>
<li>sensor data is noisy and must be shaped,</li>
<li>expressiveness requires continuous control,</li>
<li>OSC and MIDI each offer unique strengths,</li>
<li>real-time systems must feel responsive, not only correct.</li>
</ul>
<p>BEATNIK taught me to think from the <strong>performer‚Äôs perspective</strong>, not just the engineer‚Äôs.<br>
It shaped my sensitivity to latency, gesture dynamics, and expressive control ‚Äî skills that later influenced
my DSP and audio engineering work.</p>
<hr> </div><div id="project-content-dtmf_detector" data-slug="dtmf_detector"> <h1 id="dtmf-detector--goertzel-based-dsp-project">DTMF Detector ‚Äî Goertzel-based DSP Project</h1> </div><div id="project-content-laser-harp" data-slug="laser-harp"> <h1 id="laser-harp--optical-motion-based-musical-instrument">Laser Harp ‚Äî Optical Motion-Based Musical Instrument</h1>
<hr>
<h2 id="1-overview">1. Overview</h2>
<p>The <strong>Laser Harp</strong> is an optical musical instrument where each ‚Äústring‚Äù is a <strong>beam of laser light</strong>.<br>
When a performer moves their hand through a beam, the interruption is detected and translated into a:</p>
<ul>
<li><strong>MIDI note</strong>,</li>
<li><strong>OSC message</strong>, or</li>
<li><strong>control signal</strong></li>
</ul>
<p>depending on the chosen output mode.</p>
<p>The project combines:</p>
<ul>
<li>real-time embedded sensing</li>
<li>optical alignment and calibration</li>
<li>noise filtering</li>
<li>musical mapping logic</li>
<li>gestural control concepts</li>
</ul>
<hr>
<h2 id="2-problem-statement">2. Problem Statement</h2>
<p>Physical harps require string plucking.<br>
The goal here was to design a <strong>touchless</strong>, visually striking instrument that:</p>
<ul>
<li>reacts instantly to hand motion</li>
<li>avoids false triggers from ambient light</li>
<li>maps gestures to musical notes cleanly</li>
<li>is playable in low and high lighting conditions</li>
</ul>
<p>Challenges solved:</p>
<ul>
<li>optical noise from room lighting</li>
<li>sensor threshold calibration</li>
<li>fast detection of beam interruption</li>
<li>avoiding note flicker and retriggers</li>
<li>mapping multiple beams to a musical scale</li>
</ul>
<hr>
<h2 id="3-system-architecture">3. System Architecture</h2>
<h3 id="1-optical-beam-system"><strong>1. Optical Beam System</strong></h3>
<ul>
<li>Multiple laser diodes positioned vertically</li>
<li>Photodiodes or LDRs aligned opposite each laser</li>
<li>A constant laser ‚Üí photodiode reading indicates ‚Äúbeam intact‚Äù</li>
<li>A drop in sensor voltage indicates ‚Äúbeam broken‚Äù</li>
</ul>
<h3 id="2-signal-conditioning"><strong>2. Signal Conditioning</strong></h3>
<p>To create stable digital-like signals:</p>
<ul>
<li>Analog low-pass filters</li>
<li>Comparator circuits for thresholding</li>
<li>Pull-up/pull-down stabilization</li>
<li>Shielding to reduce ambient noise</li>
</ul>
<h3 id="3-embedded-controller"><strong>3. Embedded Controller</strong></h3>
<p>A microcontroller (Arduino/Teensy-level) handled:</p>
<ul>
<li>Reading photodiode outputs</li>
<li>Applying debounce logic</li>
<li>State transitions (INTACT ‚Üí BROKEN ‚Üí INTACT)</li>
<li>Generating MIDI/OSC messages</li>
</ul>
<h3 id="4-output-layer"><strong>4. Output Layer</strong></h3>
<p>Supports three modes:</p>
<h4 id="midi-mode">MIDI Mode</h4>
<ul>
<li>Note ON when the beam is broken</li>
<li>Note OFF when the beam is restored</li>
<li>Notes mapped to diatonic or chromatic scales</li>
</ul>
<h4 id="osc-mode">OSC Mode</h4>
<ul>
<li>OSC messages for:
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>/laserharp/string1</span></span>
<span class="line"><span>/laserharp/string2</span></span>
<span class="line"><span>/laserharp/string3</span></span>
<span class="line"><span></span></span></code></pre>
</li>
<li>Useful for synthesis engines like Max/MSP, Pure Data, SuperCollider</li>
</ul>
<h4 id="hybrid-mode">Hybrid Mode</h4>
<ul>
<li>Both OSC + MIDI for advanced performance rigs</li>
</ul>
<hr>
<h2 id="4-implementation-details">4. Implementation Details</h2>
<h3 id="41-photodiode-alignment">4.1 Photodiode Alignment</h3>
<ul>
<li>Required precise beam-to-sensor alignment</li>
<li>Beam intensity adjusted to prevent oversaturation</li>
<li>Ambient light tested in different environments</li>
</ul>
<h3 id="42-embedded-logic-c">4.2 Embedded Logic (C)</h3>
<p>The core loop ran at a stable frequency:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#F97583">if</span><span style="color:#E1E4E8"> (sensor_value </span><span style="color:#F97583">&#x3C;</span><span style="color:#E1E4E8"> threshold </span><span style="color:#F97583">&#x26;&#x26;</span><span style="color:#E1E4E8"> state </span><span style="color:#F97583">==</span><span style="color:#E1E4E8"> INTACT) {</span></span>
<span class="line"><span style="color:#B392F0">    trigger_note</span><span style="color:#E1E4E8">(string_id);</span></span>
<span class="line"><span style="color:#E1E4E8">    state </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> BROKEN;</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583">if</span><span style="color:#E1E4E8"> (sensor_value </span><span style="color:#F97583">></span><span style="color:#E1E4E8"> threshold </span><span style="color:#F97583">&#x26;&#x26;</span><span style="color:#E1E4E8"> state </span><span style="color:#F97583">==</span><span style="color:#E1E4E8"> BROKEN) {</span></span>
<span class="line"><span style="color:#B392F0">    release_note</span><span style="color:#E1E4E8">(string_id);</span></span>
<span class="line"><span style="color:#E1E4E8">    state </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> INTACT;</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span>
<span class="line"></span></code></pre>
<p>Additional logic:</p>
<ul>
<li>Software debounce</li>
<li>Minimum-hold timers</li>
<li>Velocity/glide options</li>
</ul>
<h3 id="43-midi-note-mapping">4.3 MIDI Note Mapping</h3>
<p>Two options:</p>
<h4 id="fixed-scale"><strong>Fixed Scale</strong></h4>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>Beam 1 ‚Üí MIDI 60 (C4)</span></span>
<span class="line"><span>Beam 2 ‚Üí MIDI 62 (D4)</span></span>
<span class="line"><span>Beam 3 ‚Üí MIDI 64 (E4)</span></span>
<span class="line"><span></span></span></code></pre>
<h4 id="dynamic-mode"><strong>Dynamic Mode</strong></h4>
<p>Pitch determined by:</p>
<ul>
<li>hand height</li>
<li>beam index</li>
<li>external scale tables</li>
</ul>
<h3 id="44-osc-mapping">4.4 OSC Mapping</h3>
<p>Example:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>/harp/beam1 1   ‚Üí beam broken</span></span>
<span class="line"><span>/harp/beam1 0   ‚Üí beam restored</span></span>
<span class="line"><span></span></span></code></pre>
<hr>
<h2 id="5-results">5. Results</h2>
<ul>
<li>Intuitive and fun to play</li>
<li>Clear on/off triggering with minimal jitter</li>
<li>Visually striking, ideal for performance</li>
<li>Low latency due to efficient embedded design</li>
</ul>
<hr>
<h2 id="6-skills-demonstrated">6. Skills Demonstrated</h2>
<ul>
<li>Embedded C development</li>
<li>Analog/digital signal conditioning</li>
<li>Real-time state machine implementation</li>
<li>MIDI and OSC output design</li>
<li>Hardware prototyping</li>
<li>UX design for interactive instruments</li>
</ul>
<hr>
<h2 id="7-narration--reflection">7. Narration / Reflection</h2>
<p>Building a <strong>touchless optical instrument</strong> taught me how environmental factors, noise, timing stability,
and physical placement influence real-time interaction.</p>
<p>A laser harp only feels ‚Äúcorrect‚Äù when triggering is instantaneous and stable.<br>
This reinforced principles that later shaped my DSP and audio engineering mindset:</p>
<ul>
<li>responsiveness matters</li>
<li>noise must be controlled</li>
<li>thresholds require tuning</li>
<li>UX is just as important as code</li>
</ul>
<hr> </div><div id="project-content-massive_mimo_seminar" data-slug="massive_mimo_seminar"> <h1 id="academic-seminar--massive-mu-mimo-downlink-with-linear-precoding-and-downlink-pilots">Academic Seminar ‚Äì Massive MU-MIMO Downlink with Linear Precoding and Downlink Pilots</h1>
<hr>
<h2 id="1-overview">1. Overview</h2>
<p>This seminar explored <strong>Massive Multi-User MIMO</strong> in TDD systems with a focus on:</p>
<ul>
<li>Linear precoding (MRT, ZF)</li>
<li>CSI acquisition</li>
<li>Beamforming-based downlink training</li>
<li>Achievable rate analysis</li>
<li>MATLAB simulations</li>
</ul>
<p>This was an <strong>academic research seminar</strong>, not industry work, and provides foundational understanding of
multi-antenna wireless systems.</p>
<hr>
<h2 id="2-problem-statement">2. Problem Statement</h2>
<p>Massive MIMO systems achieve high spectral efficiency using many antennas (M >> K), but face:</p>
<ul>
<li>CSI acquisition challenges</li>
<li>Pilot overhead</li>
<li>Inter-user interference</li>
<li>Precoding complexity</li>
</ul>
<p>The goal was to evaluate practical training schemes and achievable rate bounds under realistic constraints.</p>
<hr>
<h2 id="3-system-components">3. System Components</h2>
<ul>
<li>TDD reciprocity</li>
<li>MMSE channel estimation</li>
<li>Orthogonal pilot sequences</li>
</ul>
<h3 id="2-downlink-beamforming-pilots"><strong>2. Downlink Beamforming Pilots</strong></h3>
<p>Beamformed pilots help users estimate <strong>effective channel gain</strong>, reducing overhead from M to K.</p>
<h3 id="3-linear-precoding"><strong>3. Linear Precoding</strong></h3>
<ul>
<li>
<p><strong>MRT (Maximum Ratio Transmission)</strong></p>
<ul>
<li>Simple, high SNR behavior</li>
<li>Poor interference suppression</li>
</ul>
</li>
<li>
<p><strong>ZF (Zero-Forcing)</strong></p>
<ul>
<li>Better interference handling</li>
<li>Requires more accurate CSI</li>
</ul>
</li>
</ul>
<h3 id="4-achievable-rate-analysis"><strong>4. Achievable Rate Analysis</strong></h3>
<p>Analytical lower bounds computed for both precoding schemes.</p>
<hr>
<h2 id="4-matlab-simulations">4. MATLAB Simulations</h2>
<p>Simulated:</p>
<ul>
<li>Spectral efficiency vs SNR</li>
<li>MRT vs ZF comparison</li>
<li>Genie-aided receiver benchmarks</li>
<li>Varying coherence intervals</li>
<li>Impact of imperfect CSI</li>
</ul>
<p>Findings:</p>
<ul>
<li>ZF outperforms MRT in multi-user settings</li>
<li>Beamforming training reduces pilot overhead significantly</li>
<li>Longer coherence intervals improve achievable rates</li>
</ul>
<hr>
<h2 id="5-skills-demonstrated">5. Skills Demonstrated</h2>
<ul>
<li>Wireless system modeling</li>
<li>MATLAB simulation</li>
<li>Linear algebra for communication systems</li>
<li>Reading and summarizing research papers</li>
<li>Understanding spectral efficiency bounds</li>
</ul>
<hr>
<h2 id="6-narration">6. Narration</h2>
<p>This seminar gave me foundational insight into how large-scale antenna systems operate.
Although I don‚Äôt specialize in Massive MIMO professionally, the experience strengthened my confidence
in analyzing complex communication systems, which later supported my DSP and engineering mindset.</p>
<hr> </div><div id="project-content-multihop_wireless_warp_prototyping" data-slug="multihop_wireless_warp_prototyping"> <h1 id="multi-hop-wireless-prototyping-with-warp-sdr">Multi-Hop Wireless Prototyping with WARP SDR</h1>
<hr>
<h2 id="1-overview">1. Overview</h2>
<p>This project involved building a <strong>research-grade multi-hop wireless prototyping system</strong> using:</p>
<ul>
<li><strong>WARP SDR boards</strong></li>
<li><strong>MATLAB visualization tools</strong></li>
<li><strong>Custom data parsing and analysis scripts</strong></li>
</ul>
<p>The aim was to allow researchers and students to <strong>see and understand</strong> how packets propagate through
multi-hop and cooperative communication networks under real wireless conditions.</p>
<p>The project unified:</p>
<ul>
<li>SDR experimentation</li>
<li>Wireless communication theory</li>
<li>Data visualization</li>
<li>MATLAB GUI development</li>
<li>Research methodology</li>
</ul>
<hr>
<h2 id="2-problem-statement">2. Problem Statement</h2>
<p>Multi-hop wireless networks behave far differently in practice than in theoretical models.<br>
Difficulties include:</p>
<ul>
<li>unpredictable packet drops</li>
<li>timing misalignments between relays</li>
<li>asymmetric link quality</li>
<li>non-intuitive hop progression</li>
<li>unclear forwarding behaviors in coded vs. uncoded relays</li>
</ul>
<p>Raw logs alone make these behaviors <strong>very hard to understand</strong>.</p>
<p>Researchers needed:</p>
<p>‚úî A visualization tool<br>
‚úî Real-time or near-real-time feedback<br>
‚úî Clear multi-hop path reconstruction<br>
‚úî Comparison between forwarding schemes</p>
<hr>
<h2 id="3-system-architecture">3. System Architecture</h2>
<h3 id="1-warp-sdr-nodes"><strong>(1) WARP SDR Nodes</strong></h3>
<p>Roles included:</p>
<ul>
<li>Source</li>
<li>One or more relays</li>
<li>Destination</li>
</ul>
<p>Nodes were configured to run experiments on cooperative relaying and multi-hop forwarding.</p>
<h3 id="2-experiment-logging"><strong>(2) Experiment Logging</strong></h3>
<p>Each WARP node logged:</p>
<ul>
<li>packet arrivals</li>
<li>MAC/PHY timing</li>
<li>hop counts</li>
<li>relay decisions</li>
<li>RSSI / link quality indicators</li>
</ul>
<h3 id="3-matlab-data-interface"><strong>(3) MATLAB Data Interface</strong></h3>
<p>A MATLAB module was written to:</p>
<ul>
<li>import logs</li>
<li>parse timestamps</li>
<li>synchronize node records</li>
<li>reconstruct packet paths</li>
<li>compute per-hop statistics</li>
</ul>
<h3 id="4-matlab-visualization-gui"><strong>(4) MATLAB Visualization GUI</strong></h3>
<p>Custom GUI displayed:</p>
<ul>
<li>node topology</li>
<li>live or replayed packet flow</li>
<li>hop progression animation</li>
<li>RSSI bars</li>
<li>coded vs. uncoded performance difference</li>
<li>timelines and link behavior</li>
</ul>
<hr>
<h2 id="4-implementation-details">4. Implementation Details</h2>
<h3 id="matlab-parsing-logic">MATLAB Parsing Logic</h3>
<ul>
<li>Parsed CSV/log files from each node</li>
<li>Mapped packet IDs ‚Üí forwarding chain</li>
<li>Detected losses and duplicates</li>
<li>Aligned timestamps across nodes</li>
<li>Constructed directed graphs of packet movement</li>
</ul>
<h3 id="gui-modules">GUI Modules</h3>
<ul>
<li><strong>Topology View</strong>: nodes arranged visually, routing lines updated dynamically</li>
<li><strong>Hop Timeline</strong>: how many hops a packet took across time</li>
<li><strong>RSSI Panel</strong>: color-coded link quality</li>
<li><strong>Per-packet Playback</strong>: replay packet propagation step-by-step</li>
</ul>
<h3 id="sdr-experiment-configuration">SDR Experiment Configuration</h3>
<ul>
<li>Configured transmit power</li>
<li>Selected carrier frequency</li>
<li>Adjusted PHY parameters</li>
<li>Collected logs in controlled and noisy environments</li>
</ul>
<h3 id="data-analysis-scripts">Data Analysis Scripts</h3>
<ul>
<li>computed per-hop success rates</li>
<li>compared coded vs uncoded forwarding reliability</li>
<li>plotted latency distributions</li>
<li>identified link asymmetries</li>
</ul>
<hr>
<h2 id="5-key-findings">5. Key Findings</h2>
<p>The visualization revealed behaviors that were NOT obvious from theory:</p>
<ul>
<li><strong>Relay‚Äìdestination links behaved asymmetrically</strong>, causing unexpected drops</li>
<li><strong>Coded forwarding improved robustness</strong>, especially under low SNR</li>
<li><strong>Timing misalignment</strong> between relays caused packet duplication or premature discard</li>
<li><strong>Hop count fluctuated dynamically</strong>, depending on the wireless environment</li>
</ul>
<p>Graphs and animations provided immediate intuition about the multi-hop behavior that traditional logs
and equations could not convey.</p>
<hr>
<h2 id="6-skills-demonstrated">6. Skills Demonstrated</h2>
<h3 id="wireless-communication-engineering">Wireless Communication Engineering</h3>
<ul>
<li>Understanding of multi-hop and cooperative relaying</li>
<li>SDR hardware handling</li>
<li>Wireless measurement interpretation</li>
</ul>
<h3 id="matlab-engineering">MATLAB Engineering</h3>
<ul>
<li>GUI development</li>
<li>Data parsing / cleaning</li>
<li>Signal visualization</li>
<li>Experiment automation</li>
</ul>
<h3 id="research-workflow-skills">Research Workflow Skills</h3>
<ul>
<li>Experiment design</li>
<li>Interpretation of real channel behaviors</li>
<li>Presenting wireless concepts visually</li>
</ul>
<h3 id="systems-thinking">Systems Thinking</h3>
<ul>
<li>Bridging hardware measurements ‚Üí interpretable information</li>
<li>Making complex wireless behavior intuitive</li>
</ul>
<hr>
<h2 id="7-narration--reflection">7. Narration / Reflection</h2>
<p>This project was my first experience in turning <strong>raw wireless behavior</strong> into <strong>visual insight</strong>.</p>
<p>I realized:</p>
<ul>
<li>Real channels don‚Äôt behave like textbook channels</li>
<li>Logs are meaningless without visualization</li>
<li>Timing mismatches and asymmetric links dominate multi-hop performance</li>
<li>Visualization accelerates research understanding dramatically</li>
</ul>
<p>The project strengthened my skills in combining <strong>engineering rigor</strong>, <strong>experimental thinking</strong>, and
<strong>visual communication</strong>, which later translated directly into how I approach debugging and system
analysis in DSP and audio engineering.</p>
<hr> </div><div id="project-content-my-live-portfolio" data-slug="my-live-portfolio"> <p>‚∏ª</p>
<p>üéû My Live Portfolio</p>
<p>Why I Turned My Career Into a Living System Instead of a PDF</p>
<p>‚∏ª</p>
<p>VHS INTRO</p>
<p>This tape contains the story behind one of my most personal projects: My Live Portfolio.
It‚Äôs not a technical breakdown. It‚Äôs the ‚Äúwhy‚Äù ‚Äî the honest, slightly funny journey that started when I realised my CV no longer matched the person I‚Äôve actually become.</p>
<p>Press play to enter the archives of my own professional confusion and rediscovery.</p>
<p>‚∏ª</p>
<p>My Live Portfolio ‚Äî The Article (Polished Version)</p>
<p>I didn‚Äôt create this project because I needed another fancy section on a website.
I created it because, after years of working, I discovered something mildly disturbing:</p>
<p>My CV had become a stranger.</p>
<p>The titles were correct.
The job descriptions were accurate.
The bullet points looked well-behaved.</p>
<p>But the real substance of my work ‚Äî the problems I solved, the systems I built, the mistakes I learned from, the ideas that actually shaped me ‚Äî none of that existed on paper. Everything felt flattened and dehydrated. My career looked like an over-compressed audio file: recognisable, but missing all the richness.</p>
<p>The strangest part wasn‚Äôt that others couldn‚Äôt see it.
The strangest part was that I had forgotten half of it too.</p>
<p>‚∏ª</p>
<ol>
<li>When a PDF stops being enough</li>
</ol>
<p>It hit me when I tried to ‚Äúproperly update‚Äù my CV.
Scrolling through old sections, I realised I had to think hard just to remember certain projects I once worked on daily. Technical decisions I made confidently back then were now blurry details buried under years of new responsibilities.</p>
<p>That‚Äôs when it clicked:
A CV is not a portrait.
It‚Äôs a passport photo ‚Äî flat, tiny, and only vaguely similar to the real person.</p>
<p>I didn‚Äôt want to be represented by something that forgettable.</p>
<p>‚∏ª</p>
<ol start="2">
<li>Excavating my own past</li>
</ol>
<p>Before anything became a project, it became an excavation.</p>
<p>I opened old internship reports, thesis documents, job folders, research notes, side projects, random screenshots, and files with suspicious names like ‚Äúfinal_v3_realfinal_OK.pdf‚Äù. Some of it made me laugh. Some of it made me nostalgic. Some of it made me wonder how I ever did those things and then just‚Ä¶ moved on.</p>
<p>But the more I organised, the more overwhelming it became.
A mountain of content is still a mountain.</p>
<p>If I tried to dump all of it onto a webpage, no one would read it.
Not even me.</p>
<p>Organisation alone wasn‚Äôt enough.
I needed something that could make sense of it.</p>
<p>‚∏ª</p>
<ol start="3">
<li>What if my career could actually respond?</li>
</ol>
<p>This was the moment the idea sharpened.</p>
<p>Instead of juggling 15 versions of a CV or writing summaries for every purpose, I wondered:</p>
<p>What if my portfolio could adapt?
What if it could answer different questions?
What if it could tell different stories based on what someone needs to know?</p>
<p>What if it could link past work to future goals, without me manually rewriting everything?</p>
<p>Basically:
What if my career could talk back?</p>
<p>That‚Äôs how the idea of a Live Portfolio came to life ‚Äî a system that doesn‚Äôt display my work, but understands it.</p>
<p>‚∏ª</p>
<ol start="4">
<li>The honest human motivation</li>
</ol>
<p>Let‚Äôs be direct.
Part of this project is absolutely me refusing to let anyone judge my entire engineering life in eight seconds of CV scanning.</p>
<p>The other part is personal: I don‚Äôt want to forget who I became through all these years. Skills fade when they aren‚Äôt revisited. Memories blur. Achievements shrink when squeezed between bullet point formatting.</p>
<p>I realised I needed something alive ‚Äî something that grows with me, remembers for me, and helps me articulate my own capabilities with clarity, not guesswork.</p>
<p>‚∏ª</p>
<ol start="5">
<li>Then the engineer in me took over</li>
</ol>
<p>Emotions got me started, but systems thinking finished the idea.</p>
<p>I began treating my career like an engineering problem:
‚Ä¢	Raw data: documents, projects, roles, timelines
‚Ä¢	Structure: skills, tags, technologies, responsibilities
‚Ä¢	Meaning: what these experiences actually say about me
‚Ä¢	Outputs: narratives for specific situations
‚Ä¢	Interface: simple, natural, adaptable</p>
<p>It‚Äôs basically an encoder for my professional identity:</p>
<p>Input ‚Üí messy but meaningful journey
Output ‚Üí tailored, coherent, human explanations</p>
<p>This felt more ‚Äúme‚Äù than any CV I had ever written.</p>
<p>‚∏ª</p>
<ol start="6">
<li>What My Live Portfolio really is</li>
</ol>
<p>It is:
‚Ä¢	A rebellion against being reduced to two pages
‚Ä¢	A system that keeps my work alive instead of archived
‚Ä¢	A tool that helps me understand myself as much as others understand me
‚Ä¢	A way to tell richer stories without overwhelming people
‚Ä¢	A personal reminder of everything I‚Äôve built and learned
‚Ä¢	A project that grows as I continue evolving</p>
<p>But most of all, it‚Äôs an honest attempt to represent myself properly ‚Äî not as a static document, but as an ongoing story.</p>
<p>‚∏ª</p>
<p>VHS OUTRO</p>
<p>Tape ends here.
The emotional journey is complete.</p>
<p>If you‚Äôre curious about the technical machinery behind My Live Portfolio ‚Äî the data models, the structure, the AI logic ‚Äî that‚Äôs on a separate tape in the archive.
This one was never about the system. It was about the person building it.</p>
<p>‚∏ª</p>
<p>Back-Cover Summary</p>
<p>A reflective and slightly humorous story about why I built My Live Portfolio. After years of work compressed into a lifeless CV, I went back through my past, rediscovered forgotten projects, and realised I needed a living system that understands and expresses my career in a way a PDF never could. This article is the story behind that decision.</p>
<p>‚∏ª</p> </div><div id="project-content-parallel-av-encoding-framework" data-slug="parallel-av-encoding-framework"> <h1 id="building-an-abr-encoding-lab">Building an ABR Encoding Lab</h1>
<p>Needed: explore encoder variants quickly, measure quality, and assemble ladder candidates without hand-running FFmpeg every time. Built a Python + FFmpeg harness that ingests, fragments, runs variants, and spits out HLS/DASH artifacts with consistent logging.</p>
<p>‚∏ª</p>
<p>Ingest &#x26; fragment:</p>
<ul>
<li>Auto-detect inputs, normalize tracks, segment into fragments with stable GOP alignment.</li>
<li>Write fragment manifests so every variant keeps matching metadata.</li>
</ul>
<p>Concurrent runs:</p>
<ul>
<li>Spawn FFmpeg workers across cores; track PIDs, timeouts, per-job temp dirs.</li>
<li>Sweep GOP, tune/preset, RC mode, filters; produce fragmented MP4s per variant.</li>
<li>Concatenate select fragments into short A/B clips for quick playback checks.</li>
</ul>
<p>Metrics &#x26; packaging:</p>
<ul>
<li>Generate HLS/DASH playlists and ladders automatically from successful variants.</li>
<li>Log VMAF, PSNR, bitrate, throughput; export CSVs to compare size vs. quality.</li>
<li>Add guardrails: retries on transient failures, cleanup of orphaned processes, disk budget enforcement.</li>
</ul>
<p>Outcome: faster ladder tuning with reproducible runs, instant A/B inspection, and clear quality/bandwidth trade-offs.</p> </div><div id="project-content-parking_management_system" data-slug="parking_management_system"> <h1 id="intelligent-parking-system--embedded-c-project">Intelligent Parking System ‚Äî Embedded C Project</h1>
<hr>
<h2 id="1-overview">1. Overview</h2>
<p>The <strong>Intelligent Parking System</strong> is an embedded project designed to detect parking slot occupancy in
real time using sensors and a microcontroller. The system reports free/occupied slots on a display and
can be extended for automated gate control or IoT integration.</p>
<p>This project demonstrates:</p>
<ul>
<li>embedded C development</li>
<li>real-time sensor polling</li>
<li>decision logic</li>
<li>LCD/LED display control</li>
<li>hardware‚Äìsoftware integration</li>
</ul>
<hr>
<h2 id="2-problem-statement">2. Problem Statement</h2>
<p>Parking spaces require:</p>
<ul>
<li>clear visibility of available slots</li>
<li>fast and reliable detection</li>
<li>low-cost hardware</li>
<li>stable operation under noise</li>
</ul>
<p>Traditional systems rely on manual observation or expensive camera setups. The goal was to build a
simple, reliable embedded solution using basic sensors and microcontroller logic.</p>
<hr>
<h2 id="3-system-architecture">3. System Architecture</h2>
<h3 id="components">Components</h3>
<ul>
<li>Microcontroller (e.g., AVR, PIC, or Arduino-class)</li>
<li>Ultrasonic or IR sensors for vehicle detection</li>
<li>LCD/LED display module</li>
<li>Optional buzzer/indicator lights</li>
<li>Power regulation and wiring</li>
</ul>
<h3 id="architecture-flow">Architecture Flow</h3>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>Sensors ‚Üí Microcontroller ‚Üí Decision Logic ‚Üí Display Output</span></span>
<span class="line"><span></span></span></code></pre>
<h3 id="detection-logic">Detection Logic</h3>
<ul>
<li>Each sensor monitors a parking slot.</li>
<li>Sensor readings converted to digital occupancy state.</li>
<li>Microcontroller aggregates results and updates the display.</li>
</ul>
<hr>
<h2 id="4-implementation-details">4. Implementation Details</h2>
<h3 id="embedded-c-logic">Embedded C Logic</h3>
<p>Key functions:</p>
<ul>
<li>Initialization of GPIO and sensor interfaces</li>
<li>Continuous sampling loop</li>
<li>Threshold-based detection</li>
<li>Debounce and filtering to avoid false triggers</li>
<li>Display update routines</li>
</ul>
<p>Example pseudocode:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#F97583">if</span><span style="color:#E1E4E8"> (distance </span><span style="color:#F97583">&#x3C;</span><span style="color:#E1E4E8"> threshold </span><span style="color:#F97583">&#x26;&#x26;</span><span style="color:#E1E4E8"> state </span><span style="color:#F97583">==</span><span style="color:#E1E4E8"> EMPTY) {</span></span>
<span class="line"><span style="color:#E1E4E8">    state </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> OCCUPIED;</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583">if</span><span style="color:#E1E4E8"> (distance </span><span style="color:#F97583">></span><span style="color:#E1E4E8"> threshold </span><span style="color:#F97583">&#x26;&#x26;</span><span style="color:#E1E4E8"> state </span><span style="color:#F97583">==</span><span style="color:#E1E4E8"> OCCUPIED) {</span></span>
<span class="line"><span style="color:#E1E4E8">    state </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> EMPTY;</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span>
<span class="line"></span></code></pre>
<h3 id="filtering--stability">Filtering &#x26; Stability</h3>
<ul>
<li>Simple moving average to reduce noise</li>
<li>Minimum-change thresholding</li>
<li>Timing delays to prevent rapid toggling</li>
</ul>
<h3 id="display-output">Display Output</h3>
<ul>
<li>Number of free slots</li>
<li>Visual indicators for each slot</li>
<li>Optional arrow signs or buzzer for user guidance</li>
</ul>
<hr>
<h2 id="5-results">5. Results</h2>
<ul>
<li>Accurate detection in typical parking environments</li>
<li>Low jitter after filtering</li>
<li>Easy-to-read status output</li>
<li>Low-cost hardware footprint</li>
<li>Reliable operation under continuous polling</li>
</ul>
<hr>
<h2 id="6-skills-demonstrated">6. Skills Demonstrated</h2>
<ul>
<li>Embedded C programming</li>
<li>Sensor integration (IR/ultrasonic)</li>
<li>Real-time signal filtering</li>
<li>State-machine logic</li>
<li>Display interfacing (LCD/LED)</li>
<li>Debugging hardware‚Äìsoftware interactions</li>
</ul>
<hr>
<h2 id="7-narration--reflection">7. Narration / Reflection</h2>
<p>This project helped me understand how real-time embedded systems behave under real-world noise and
sensor inconsistency. Building a robust detection pipeline taught me fundamentals of:</p>
<ul>
<li>threshold tuning</li>
<li>debounce strategies</li>
<li>display synchronization</li>
<li>embedded timing constraints</li>
</ul>
<p>It was one of the earliest projects where I saw how <strong>simple sensing + reliable logic</strong> can create a usable,
real-world system.</p>
<hr> </div><div id="project-content-post-processing-separated-speech" data-slug="post-processing-separated-speech"> <h1 id="master-thesis--speech-bandwidth-extension-using-non-linear-post-processing">Master Thesis ‚Äî Speech Bandwidth Extension Using Non-Linear Post-Processing</h1>
<hr>
<h2 id="1-overview">1. Overview</h2>
<p>This thesis focused on reconstructing <strong>wideband speech</strong> from narrowband (telephone-band) input
using <strong>non-linear post-processing</strong>, <strong>excitation modelling</strong>, and <strong>spectral envelope reconstruction</strong>.
The goal was to increase perceived bandwidth, restore brightness, and improve naturalness <strong>without</strong>
requiring changes to the encoder or any side information.</p>
<p>The work brought together:</p>
<ul>
<li>Digital signal processing theory (LPC, source‚Äìfilter models)</li>
<li>Practical system design</li>
<li>MATLAB &#x26; Python prototyping</li>
<li>Perceptual audio evaluation and tuning</li>
<li>Iterative refinement based on listening tests and spectral analysis</li>
</ul>
<hr>
<h2 id="2-problem-statement">2. Problem Statement</h2>
<p>Traditional narrowband speech (0‚Äì4 kHz) loses:</p>
<ul>
<li>High-frequency harmonics</li>
<li>Brightness and ‚Äúair‚Äù</li>
<li>Natural articulation cues</li>
<li>Wideband timbral characteristics</li>
</ul>
<p>The challenge is reconstructing plausible high-band components <strong>from missing information</strong>, not noisy
information. This is fundamentally an <strong>ill-posed inverse problem</strong>, requiring:</p>
<ul>
<li>Excitation generation</li>
<li>Envelope reconstruction</li>
<li>Stability against artifacts</li>
<li>Low computational cost</li>
</ul>
<p>Goal:<br>
Produce <strong>wideband-like speech</strong> that is perceptually convincing and spectrally coherent.</p>
<hr>
<h2 id="3-system-architecture">3. System Architecture</h2>
<p>The thesis designed a processing chain consisting of:</p>
<h3 id="1-narrowband-analysis"><strong>(1) Narrowband Analysis</strong></h3>
<ul>
<li>Pre-emphasis</li>
<li>Windowing</li>
<li>LPC analysis (10‚Äì14th order)</li>
<li>Extraction of the excitation signal</li>
</ul>
<h3 id="2-excitation-modelling"><strong>(2) Excitation Modelling</strong></h3>
<p>Tested approaches included:</p>
<ul>
<li>Non-linear expansion</li>
<li>Odd/even harmonic generation</li>
<li>Sign-preserving power functions</li>
<li>Spectral folding</li>
<li>Blended excitation shaping</li>
</ul>
<p>The final system used <strong>non-linear excitation expansion</strong> with a <strong>high-band shaping filter</strong>.</p>
<h3 id="3-envelope-reconstruction"><strong>(3) Envelope Reconstruction</strong></h3>
<p>Methods explored:</p>
<ul>
<li>LPC envelope extrapolation</li>
<li>High-band envelope smoothing</li>
<li>Adaptive energy matching</li>
<li>Band-tilting adjustments</li>
</ul>
<h3 id="4-synthesis"><strong>(4) Synthesis</strong></h3>
<ul>
<li>Excitation filtering using reconstructed LPC coefficients</li>
<li>Overlap‚Äìadd synthesis</li>
<li>Envelope smoothing and final spectral correction</li>
</ul>
<hr>
<h2 id="4-block-diagram-textual">4. Block Diagram (Textual)</h2>
<p>Narrowband Speech
‚Üì
Analysis
(LPC, excitation)
‚Üì
Non-linear Excitation Expansion
‚Üì
High-band Spectral Shaping
‚Üì
Envelope Reconstruction
‚Üì
Synthesis
‚Üì
Enhanced Wideband-like Speech</p>
<hr>
<h2 id="5-implementation-details">5. Implementation Details</h2>
<h3 id="matlab-prototyping">MATLAB Prototyping</h3>
<ul>
<li>LPC extraction (autocorrelation &#x26; Burg methods)</li>
<li>Excitation expansion experiments</li>
<li>Envelope smoothing filters</li>
<li>Spectral envelope visualization</li>
<li>Objective metrics:
<ul>
<li>log-spectral distance (LSD)</li>
<li>harmonic envelope deviation</li>
</ul>
</li>
</ul>
<h3 id="python-experiments">Python Experiments</h3>
<ul>
<li>Rapid testing of excitation functions</li>
<li>Plotting envelope differences</li>
<li>Generating spectrograms and comparison views</li>
<li>Automating batch evaluation sets</li>
</ul>
<hr>
<h2 id="6-evaluation-strategy">6. Evaluation Strategy</h2>
<h3 id="objective-measures">Objective Measures</h3>
<ul>
<li>High-band energy reconstruction accuracy</li>
<li>Envelope shape similarity</li>
<li>Temporal smoothness</li>
</ul>
<h3 id="perceptual-evaluation">Perceptual Evaluation</h3>
<p>Performed <strong>A/B and A/B/X listening tests</strong> on:</p>
<ul>
<li>Male + female speech</li>
<li>Different languages</li>
<li>Varied articulation patterns</li>
<li>Clean vs. challenging content</li>
</ul>
<p>Artifacts tracked and tuned:</p>
<ul>
<li>Metallic ringing</li>
<li>Whistle-like tones</li>
<li>Synthetic ‚Äúhiss‚Äù</li>
<li>Harsh high-frequency energy</li>
<li>Energy mismatch between narrowband and high-band</li>
</ul>
<p><strong>Perceptual testing was essential</strong> ‚Äî many methods that looked good numerically produced
unacceptable artifacts during listening.</p>
<hr>
<h2 id="7-key-results">7. Key Results</h2>
<ul>
<li>Reconstructed high-band content <strong>significantly improved</strong> perceived brightness and clarity.</li>
<li>Non-linear excitation + spectral shaping produced stable and natural-sounding results.</li>
<li>High-band envelope reconstruction matched reference wideband behavior well.</li>
<li>Objective and subjective evaluations aligned closely after tuning.</li>
</ul>
<hr>
<h2 id="8-skills-demonstrated">8. Skills Demonstrated</h2>
<h3 id="dsp-expertise">DSP Expertise</h3>
<ul>
<li>LPC modelling</li>
<li>Excitation generation</li>
<li>Non-linear processing</li>
<li>Envelope shaping</li>
<li>Filter design</li>
<li>Time‚Äìfrequency analysis</li>
</ul>
<h3 id="prototyping-skills">Prototyping Skills</h3>
<ul>
<li>MATLAB algorithm development</li>
<li>Python batch experiments + visualization</li>
<li>Handling multi-file evaluation pipelines</li>
</ul>
<h3 id="perceptual-engineering">Perceptual Engineering</h3>
<ul>
<li>Systematic listening test methodology</li>
<li>Artifact identification</li>
<li>Iterative tuning based on perceptual + spectral evidence</li>
</ul>
<h3 id="research--documentation">Research &#x26; Documentation</h3>
<ul>
<li>Reproducible experiments</li>
<li>Clear reporting of results</li>
<li>Scientific and engineering communication</li>
</ul>
<hr>
<h2 id="9-narration--personal-reflection">9. Narration / Personal Reflection</h2>
<p>This thesis shaped my understanding of audio engineering at a deep level.<br>
I learned that:</p>
<ul>
<li>A mathematically ‚Äúcorrect‚Äù algorithm may still sound terrible.</li>
<li>Spectral plots, excitation behavior, and envelopes must align with what listeners perceive.</li>
<li>Perceptual tuning is a <strong>core part of DSP</strong>, not an afterthought.</li>
</ul>
<p>The project taught me to think simultaneously like a:</p>
<ul>
<li><strong>scientist</strong> (theory, modelling)</li>
<li><strong>engineer</strong> (system design, prototyping)</li>
<li><strong>listener</strong> (perception, artifacts, tuning)</li>
</ul>
<p>This balance between <strong>math, engineering, and human hearing</strong> continues to define how I approach
audio, DSP, and media systems today.</p>
<hr> </div><div id="project-content-traffic_signal_controller" data-slug="traffic_signal_controller"> <h1 id="traffic-signal-controller--embedded-c-state-machine">Traffic Signal Controller ‚Äî Embedded C State Machine</h1>
<hr>
<h2 id="1-overview">1. Overview</h2>
<p>This project implements a <strong>Traffic Signal Controller</strong> using an embedded microcontroller and a<br>
<strong>finite state machine (FSM)</strong>. The system handles:</p>
<ul>
<li>red / yellow / green cycle timing</li>
<li>safe state transitions</li>
<li>pedestrian or extended-timing modes (optional)</li>
<li>real-time light switching logic</li>
</ul>
<p>It demonstrates real-time embedded programming, state-machine design, and stable time-driven logic.</p>
<hr>
<h2 id="2-problem-statement">2. Problem Statement</h2>
<p>Traffic signals must operate:</p>
<ul>
<li>predictably</li>
<li>safely</li>
<li>with strict timing control</li>
<li>without glitches or ambiguous states</li>
</ul>
<p>A naive implementation (e.g., delays or manual toggles) is unreliable.<br>
A proper FSM is needed to ensure:</p>
<ul>
<li>correct sequence ‚Üí Red ‚Üí Green ‚Üí Yellow ‚Üí Red</li>
<li>timing consistency</li>
<li>no illegal combinations</li>
<li>clean reset behavior</li>
</ul>
<hr>
<h2 id="3-system-architecture">3. System Architecture</h2>
<h3 id="hardware-components"><strong>Hardware Components</strong></h3>
<ul>
<li>Microcontroller (AVR / PIC / Arduino-class)</li>
<li>LED indicators:
<ul>
<li>Red</li>
<li>Yellow</li>
<li>Green</li>
</ul>
</li>
<li>Timer module or software timer</li>
<li>Optional input button (e.g., pedestrian mode)</li>
</ul>
<h3 id="state-machine-diagram"><strong>State Machine Diagram</strong></h3>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>      [RED]</span></span>
<span class="line"><span>        |</span></span>
<span class="line"><span>        v</span></span>
<span class="line"><span>     [GREEN]</span></span>
<span class="line"><span>        |</span></span>
<span class="line"><span>        v</span></span>
<span class="line"><span>     [YELLOW]</span></span>
<span class="line"><span>        |</span></span>
<span class="line"><span>        v</span></span>
<span class="line"><span>      [RED]  (loop)</span></span>
<span class="line"><span></span></span></code></pre>
<h3 id="state-definitions"><strong>State Definitions</strong></h3>

























<table><thead><tr><th>State</th><th>Lights Active</th><th>Duration</th></tr></thead><tbody><tr><td>RED</td><td>Red ON</td><td>t_red</td></tr><tr><td>GREEN</td><td>Green ON</td><td>t_green</td></tr><tr><td>YELLOW</td><td>Yellow ON</td><td>t_yellow</td></tr></tbody></table>
<hr>
<h2 id="4-implementation-details">4. Implementation Details</h2>
<h3 id="41-fsm-structure-c">4.1 FSM Structure (C)</h3>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#F97583">enum</span><span style="color:#E1E4E8"> state { RED, GREEN, YELLOW };</span></span>
<span class="line"><span style="color:#F97583">enum</span><span style="color:#E1E4E8"> state current_state </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> RED;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583">void</span><span style="color:#B392F0"> loop</span><span style="color:#E1E4E8">() {</span></span>
<span class="line"><span style="color:#F97583">    switch</span><span style="color:#E1E4E8">(current_state) {</span></span>
<span class="line"><span style="color:#F97583">        case</span><span style="color:#E1E4E8"> RED:</span></span>
<span class="line"><span style="color:#B392F0">            red_on</span><span style="color:#E1E4E8">(); </span><span style="color:#B392F0">green_off</span><span style="color:#E1E4E8">(); </span><span style="color:#B392F0">yellow_off</span><span style="color:#E1E4E8">();</span></span>
<span class="line"><span style="color:#B392F0">            wait</span><span style="color:#E1E4E8">(t_red);</span></span>
<span class="line"><span style="color:#E1E4E8">            current_state </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> GREEN;</span></span>
<span class="line"><span style="color:#F97583">            break</span><span style="color:#E1E4E8">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583">        case</span><span style="color:#E1E4E8"> GREEN:</span></span>
<span class="line"><span style="color:#B392F0">            green_on</span><span style="color:#E1E4E8">(); </span><span style="color:#B392F0">red_off</span><span style="color:#E1E4E8">(); </span><span style="color:#B392F0">yellow_off</span><span style="color:#E1E4E8">();</span></span>
<span class="line"><span style="color:#B392F0">            wait</span><span style="color:#E1E4E8">(t_green);</span></span>
<span class="line"><span style="color:#E1E4E8">            current_state </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> YELLOW;</span></span>
<span class="line"><span style="color:#F97583">            break</span><span style="color:#E1E4E8">;</span></span>
<span class="line"></span>
<span class="line"><span style="color:#F97583">        case</span><span style="color:#E1E4E8"> YELLOW:</span></span>
<span class="line"><span style="color:#B392F0">            yellow_on</span><span style="color:#E1E4E8">(); </span><span style="color:#B392F0">red_off</span><span style="color:#E1E4E8">(); </span><span style="color:#B392F0">green_off</span><span style="color:#E1E4E8">();</span></span>
<span class="line"><span style="color:#B392F0">            wait</span><span style="color:#E1E4E8">(t_yellow);</span></span>
<span class="line"><span style="color:#E1E4E8">            current_state </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> RED;</span></span>
<span class="line"><span style="color:#F97583">            break</span><span style="color:#E1E4E8">;</span></span>
<span class="line"><span style="color:#E1E4E8">    }</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span>
<span class="line"></span></code></pre>
<h3 id="42-timer-integration">4.2 Timer Integration</h3>
<ul>
<li>Using hardware timers or non-blocking timing loops</li>
<li>Ensures system remains responsive</li>
</ul>
<h3 id="43-optional-pedestrian-handling">4.3 Optional Pedestrian Handling</h3>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="c"><code><span class="line"><span style="color:#F97583">if</span><span style="color:#E1E4E8"> (</span><span style="color:#B392F0">button_pressed</span><span style="color:#E1E4E8">() </span><span style="color:#F97583">&#x26;&#x26;</span><span style="color:#B392F0"> safe_to_interrupt</span><span style="color:#E1E4E8">()) {</span></span>
<span class="line"><span style="color:#B392F0">    extend_red_phase</span><span style="color:#E1E4E8">();</span></span>
<span class="line"><span style="color:#E1E4E8">}</span></span>
<span class="line"></span></code></pre>
<h3 id="44-safety-guarantees">4.4 Safety Guarantees</h3>
<ul>
<li>Never GREEN + RED at the same time</li>
<li>Minimum time per state is enforced</li>
<li>Guaranteed sequence order</li>
<li>Optional emergency all-red mode</li>
</ul>
<hr>
<h2 id="5-results">5. Results</h2>
<ul>
<li>Smooth, predictable transitions</li>
<li>Timing accuracy and stability</li>
<li>Extensible to multi-intersection control</li>
<li>No illegal LED combinations</li>
<li>Reliable due to strict FSM structure</li>
</ul>
<hr>
<h2 id="6-skills-demonstrated">6. Skills Demonstrated</h2>
<ul>
<li>Embedded C</li>
<li>State machine design</li>
<li>Real-time logic</li>
<li>Timing systems</li>
<li>IO interfacing</li>
<li>Debugging embedded timing issues</li>
</ul>
<hr>
<h2 id="7-narration--reflection">7. Narration / Reflection</h2>
<p>This project taught me the importance of deterministic timing and clean control flow.<br>
Using a state machine made the behavior predictable and easy to reason about ‚Äî an approach that applies
not only to embedded systems but also to larger software and DSP pipelines.</p>
<hr> </div><div id="project-content-vidi" data-slug="vidi"> <h1 id="vidi--low-latency-reliable-pitch-detection--pitch-shifting-tool">VIDI ‚Äî Low-Latency, Reliable Pitch Detection &#x26; Pitch-Shifting Tool</h1>
<hr>
<h2 id="1-overview">1. Overview</h2>
<p><strong>VIDI</strong> is a real-time pitch detection and pitch-shifting tool designed for musicians who need<br>
<strong>fast, stable, low-latency pitch tracking</strong> ‚Äî even in noisy rooms or during rapid melodic passages.</p>
<p>Instead of relying on a single pitch detection method, VIDI fuses multiple DSP techniques to provide
confidence-weighted pitch estimates that:</p>
<ul>
<li><strong>lock quickly</strong>,</li>
<li><strong>don‚Äôt drift</strong>,</li>
<li><strong>remain stable under noise</strong>, and</li>
<li><strong>produce natural, musical pitch shifts</strong> without chipmunk artifacts.</li>
</ul>
<p>It was built with <strong>Core Audio</strong> and <strong>vDSP</strong>, optimized for <strong>mobile-class hardware</strong> with strict
latency and performance constraints.</p>
<hr>
<h2 id="2-problem-statement">2. Problem Statement</h2>
<p>Musicians need pitch tools that work <strong>live</strong>, not only in ideal studio conditions.<br>
Most existing systems fail in at least one area:</p>
<ul>
<li>too sensitive to noise</li>
<li>unstable on fast notes</li>
<li>slow lock-in time</li>
<li>robotic or chipmunk-like pitch shifts</li>
<li>MIDI output that drifts under load</li>
</ul>
<p>VIDI solves these by combining multiple pitch algorithms and stabilizing them through DSP fusion.</p>
<hr>
<h2 id="3-system-architecture">3. System Architecture</h2>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>Incoming Audio  </span></span>
<span class="line"><span>      ‚Üì  </span></span>
<span class="line"><span>Frame Processing (Core Audio)  </span></span>
<span class="line"><span>      ‚Üì  </span></span>
<span class="line"><span>Parallel Pitch Estimators (AMDF / Autocorrelation / HPS)  </span></span>
<span class="line"><span>      ‚Üì  </span></span>
<span class="line"><span>Confidence Fusion Engine  </span></span>
<span class="line"><span>      ‚Üì  </span></span>
<span class="line"><span>Formant-Aware Pitch Shifting  </span></span>
<span class="line"><span>      ‚Üì  </span></span>
<span class="line"><span>Low-Latency MIDI Output  </span></span>
<span class="line"><span></span></span></code></pre>
<hr>
<h2 id="4-key-dsp-components">4. Key DSP Components</h2>
<h3 id="41-parallel-pitch-detection-engines"><strong>4.1 Parallel Pitch Detection Engines</strong></h3>
<p>VIDI runs three pitch detectors concurrently:</p>
<h4 id="1-amdf-average-magnitude-difference-function">(1) <strong>AMDF (Average Magnitude Difference Function)</strong></h4>
<ul>
<li>Excellent for fast passages</li>
<li>Good resolution for monophonic signals</li>
<li>Works well in noisy conditions</li>
</ul>
<h4 id="2-autocorrelation">(2) <strong>Autocorrelation</strong></h4>
<ul>
<li>Stable periodicity detection</li>
<li>Helps reduce octave errors</li>
<li>Provides reliable fundamentals</li>
</ul>
<h4 id="3-harmonic-product-spectrum-hps">(3) <strong>Harmonic Product Spectrum (HPS)</strong></h4>
<ul>
<li>FFT-based approach using harmonic reinforcement</li>
<li>Useful for strong harmonic structures</li>
<li>Helps refine ambiguous pitch regions</li>
</ul>
<hr>
<h3 id="42-confidence-weighted-fusion"><strong>4.2 Confidence-Weighted Fusion</strong></h3>
<p>Results are combined using a confidence score per method:</p>
<ul>
<li>consistency across methods</li>
<li>signal periodicity</li>
<li>harmonic energy distribution</li>
<li>AMDF minima stability</li>
<li>autocorrelation peak clarity</li>
</ul>
<p>The fusion engine outputs a <strong>single, stable pitch value</strong> resistant to noise and instability.</p>
<hr>
<h2 id="5-low-latency-architecture">5. Low-Latency Architecture</h2>
<h3 id="core-audio--vdsp-pipeline"><strong>Core Audio + vDSP Pipeline</strong></h3>
<p>VIDI uses:</p>
<ul>
<li><strong>Core Audio render callbacks</strong> for sub-10 ms frame processing</li>
<li><strong>vDSP FFTs</strong> for spectral methods</li>
<li>Hot loop optimizations:
<ul>
<li>inlining critical operations</li>
<li>avoiding unnecessary heap allocations</li>
<li>tight C loops for AMDF</li>
<li>vectorized operations where beneficial</li>
</ul>
</li>
</ul>
<h3 id="performance-targets">Performance Targets</h3>
<ul>
<li><strong>Frame size:</strong> 64‚Äì128 samples</li>
<li><strong>Latency budget:</strong> configurable, typically 10‚Äì20 ms end-to-end</li>
<li><strong>CPU footprint:</strong> optimized for mobile processors</li>
</ul>
<hr>
<h2 id="6-formant-aware-pitch-shifting">6. Formant-Aware Pitch Shifting</h2>
<p>Standard pitch shifting introduces:</p>
<ul>
<li>chipmunk vocals</li>
<li>unnatural brightness</li>
<li>timbre distortion</li>
</ul>
<p>VIDI avoids this with:</p>
<ul>
<li><strong>formant tracking</strong></li>
<li><strong>spectral envelope estimation</strong></li>
<li><strong>formant-preserving warping</strong></li>
<li>blending PSOLA-like and phase-vocoder concepts</li>
</ul>
<p>Result: <strong>natural, human-sounding pitch shifts</strong>, even at large intervals.</p>
<hr>
<h2 id="7-midi-output-engine">7. MIDI Output Engine</h2>
<p>VIDI generates highly stable MIDI output:</p>
<ul>
<li>configurable smoothing</li>
<li>hysteresis to reduce jitter</li>
<li>velocity modeling based on onset detection</li>
<li>guarantee of no timing drift under CPU load</li>
</ul>
<p>Compatible with:</p>
<ul>
<li>Ableton Live</li>
<li>Logic Pro</li>
<li>FL Studio</li>
<li>Max/MSP</li>
<li>Hardware synthesizers</li>
</ul>
<hr>
<h2 id="8-results">8. Results</h2>
<p>VIDI delivered:</p>
<ul>
<li><strong>fast pitch lock-in</strong></li>
<li><strong>stable tracking</strong> even with noise</li>
<li><strong>natural pitch shifts</strong> without artifacts</li>
<li><strong>low latency</strong>, suitable for live use</li>
<li><strong>accurate MIDI output</strong></li>
</ul>
<p>Musicians rated it as:</p>
<ul>
<li>predictable</li>
<li>responsive</li>
<li>expressive</li>
<li>trustworthy in live performance</li>
</ul>
<hr>
<h2 id="9-skills-demonstrated">9. Skills Demonstrated</h2>
<ul>
<li>DSP algorithm design</li>
<li>Multi-method pitch estimation</li>
<li>Confidence scoring &#x26; fusion</li>
<li>vDSP FFT optimization</li>
<li>Core Audio real-time pipelines</li>
<li>Formant-preserving pitch shifting</li>
<li>MIDI integration</li>
<li>Low-latency engineering</li>
<li>Performance optimization</li>
</ul>
<hr>
<h2 id="10-narration--reflection">10. Narration / Reflection</h2>
<p>VIDI was a significant step in understanding <strong>real-time DSP under real-world constraints</strong>.<br>
I learned how:</p>
<ul>
<li>AMDF + autocorrelation + HPS complement one another</li>
<li>confidence fusion stabilizes noisy estimates</li>
<li>low-latency budgets drive architectural choices</li>
<li>musicians value <em>feel</em> as much as technical accuracy</li>
</ul>
<p>VIDI fused <strong>DSP theory</strong>, <strong>musical sensitivity</strong>, and <strong>engineering practicality</strong>, shaping how I approach
audio systems, performance tuning, and perceptually meaningful DSP.</p>
<hr> </div> </div> </section> <script type="application/json" id="projectData">
      {JSON.stringify(projectData).replace(/</g, '\\u003c')}
    </script> <script>
      // Activate section divider animation on load
      document.addEventListener('DOMContentLoaded', () => {
        const divider = document.querySelector('.section-divider');
        if (divider) {
          requestAnimationFrame(() => {
            divider.classList.add('active');
          });
        }
      });

      const projectDataNode = document.getElementById('projectData');
      let projectData = [];
      try {
        projectData = projectDataNode ? JSON.parse(projectDataNode.textContent || '[]') : [];
      } catch (err) {
        console.error('Unable to parse project data JSON', err);
      }
      if (!Array.isArray(projectData) || projectData.length === 0) {
        // Fallback: derive from server-rendered cards if JSON failed
        projectData = Array.from(document.querySelectorAll('.vhs-item')).map((el) => {
          const tagStr = el.dataset.tags || '';
          return {
            slug: el.dataset.slug || '',
            title: el.dataset.title || el.querySelector('.vhs-spine-text')?.textContent?.trim() || '',
            year: el.dataset.year || '',
            format: el.dataset.format || '',
            code: el.dataset.code || '',
            desc: el.dataset.desc || '',
            tags: tagStr ? tagStr.split(',').filter(Boolean) : [],
            image: el.dataset.image || '',
            articleSlug: el.dataset.article || el.dataset.slug || ''
          };
        });
      }
      const storedContent = new Map();
      document.querySelectorAll('#projectContentStore [data-slug]').forEach((node) => {
        const slug = node.dataset.slug || '';
        storedContent.set(slug, node.innerHTML);
      });

      const MAX_TAGS = 10;
      let allowedTagsSet = null;
      let galleryShown = false;

      async function ensureAllowedTags() {
        if (allowedTagsSet) return allowedTagsSet;
        try {
          const res = await fetch('/data/tags.json', { cache: 'no-cache' });
          if (!res.ok) throw new Error('tags.json fetch failed');
          const arr = await res.json();
          allowedTagsSet = new Set(
            Array.isArray(arr)
              ? arr.map((t) => String(t).trim()).filter(Boolean)
              : []
          );
        } catch (err) {
          console.warn('Unable to load central tag list; skipping validation.', err);
          allowedTagsSet = new Set();
        }
        return allowedTagsSet;
      }

      const container = document.getElementById('galleryContainer');
      const filterContainer = document.getElementById('archiveFilters');
      const filterPanel = document.getElementById('filterPanel');
      const filterToggle = document.getElementById('filterToggle');
      const filterPanelClose = document.getElementById('filterPanelClose');
      const filterPanelBackdrop = document.getElementById('filterPanelBackdrop');
      const filterSearchInput = document.getElementById('filterSearchInput');
      const filterCount = document.getElementById('filterCount');
      const selectedTagsPreview = document.getElementById('selectedTagsPreview');
      const detailTitle = document.getElementById('detailTitle');
      const detailSummary = document.getElementById('detailSummary');
      const detailDesc = document.getElementById('detailDesc');
      const detailContent = document.getElementById('detailContent');
      const detailYear = document.getElementById('detailYear');
      const detailTags = document.getElementById('detailTags');
      const detailActions = document.getElementById('detailActions');
      const detailToc = document.getElementById('detailToc');
      if (container) container.classList.add('loading');

      const setDetailTitle = (text) => {
        if (!detailTitle) return;
        const span = detailTitle.querySelector('span');
        if (span) span.textContent = text;
        else detailTitle.textContent = text;
        detailTitle.classList.remove('active');
        void detailTitle.offsetWidth;
        detailTitle.classList.add('active');
      };

      const setDetailSummary = (text) => {
        if (!detailSummary) return;
        detailSummary.textContent = text || '';
      };

      const setDetailBodyMessage = (text) => {
        if (!detailDesc) return;
        detailDesc.textContent = text || '';
        detailDesc.style.display = text ? '' : 'none';
      };

      const stripHeaderAndSummary = (html) => {
        try {
          const doc = new DOMParser().parseFromString(html, 'text/html');
          const firstHeading = doc.body.querySelector('h1');
          if (firstHeading) firstHeading.remove();
          const firstParagraph = doc.body.querySelector('p');
          if (firstParagraph) firstParagraph.remove();
          doc.body.querySelectorAll('hr').forEach((node) => node.remove());
          return doc.body.innerHTML;
        } catch (err) {
          return html;
        }
      };

      const enhanceMarkdownRendering = (html) => {
        if (!html) return html;
        try {
          const doc = new DOMParser().parseFromString(html, 'text/html');
          
          // Convert divider paragraphs (‚∏ª) to styled dividers
          const paragraphs = doc.body.querySelectorAll('p');
          paragraphs.forEach((p) => {
            const text = p.textContent.trim();
            const isDivider = ['‚∏ª', '---', '‚Äî‚Äî'].includes(text);
            const isInlineDivider = text.startsWith('‚∏ª') || text.endsWith('‚∏ª');
            if (isDivider) {
              const prev = p.previousElementSibling;
              const next = p.nextElementSibling;
              const adjacentToHeading = [prev, next].some(
                (node) => node && /^H[1-6]$/.test(node.tagName)
              );
              if (!prev || adjacentToHeading) {
                p.remove();
                return;
              }
              const divider = doc.createElement('div');
              divider.className = 'detail-divider';
              divider.innerHTML = '<span class="divider-line"></span>';
              p.replaceWith(divider);
            } else if (isInlineDivider) {
              const cleanText = text.replace(/‚∏ª/g, '').trim();
              if (cleanText) {
                p.textContent = cleanText;
              } else {
                const divider = doc.createElement('div');
                divider.className = 'detail-divider';
                divider.innerHTML = '<span class="divider-line"></span>';
                p.replaceWith(divider);
              }
            }
          });

          // Ensure proper heading hierarchy
          let headingLevel = 0;
          doc.body.querySelectorAll('h1, h2, h3, h4, h5, h6').forEach((heading) => {
            const level = parseInt(heading.tagName.charAt(1));
            if (level <= headingLevel) {
              // Convert to appropriate heading level
              const newLevel = Math.min(headingLevel + 1, 4);
              const newHeading = doc.createElement(`h${newLevel}`);
              newHeading.innerHTML = heading.innerHTML;
              heading.replaceWith(newHeading);
              headingLevel = newLevel;
            } else {
              headingLevel = level;
            }
          });

          // Clean up empty paragraphs
          doc.body.querySelectorAll('p').forEach((p) => {
            if (!p.textContent.trim() && !p.querySelector('img, br')) {
              p.remove();
            }
          });

          return doc.body.innerHTML;
        } catch (err) {
          console.warn('Error enhancing markdown:', err);
          return html;
        }
      };

      const finishGalleryLoading = () => {
        if (!container || galleryShown) return;
        galleryShown = true;
        requestAnimationFrame(() => requestAnimationFrame(() => container.classList.remove('loading')));
      };

      let activeIndex = -1;
      let activeTags = [];
      let centerActiveOnRender = false;
      let archiveData = [];
      let allTags = [];
      const contentCache = new Map();
      storedContent.forEach((html, slug) => {
        contentCache.set(slug, html);
      });

      function deriveTitleFromSlug(value) {
        if (!value) return 'Project';
        return value
          .replace(/_/g, '-')
          .split('-')
          .filter(Boolean)
          .map((word) => word.charAt(0).toUpperCase() + word.slice(1))
          .join(' ');
      }

      async function loadProjects() {
        try {
          await ensureAllowedTags();
          const hasAllowlist = allowedTagsSet && allowedTagsSet.size > 0;
          archiveData = projectData.map((item) => {
            const tags = Array.isArray(item.tags)
              ? item.tags
                  .map((t) => String(t).trim())
                  .filter(Boolean)
              : [];
            const filteredTags = hasAllowlist ? tags.filter((t) => allowedTagsSet.has(t)) : tags;
            return {
              ...item,
              tags: filteredTags.slice(0, MAX_TAGS),
              title: item.title || deriveTitleFromSlug(item.slug)
            };
          });
          if (!archiveData.length) throw new Error('No projects loaded');

          allTags = Array.from(new Set(archiveData.flatMap((item) => item.tags || [])));
          renderFilters();
          renderSelectedTagsPreview();
          updateFilterCount();
          renderGallery();
          requestAnimationFrame(centerGalleryToMiddle);
        } catch (err) {
          console.error(err);
          setDetailTitle('Unable to load projects');
          setDetailSummary('Unable to load project summary.');
          setDetailBodyMessage('Please try again later.');
          finishGalleryLoading();
        }
      }

      const getFilteredData = () =>
        activeTags.length === 0 ? archiveData : archiveData.filter((item) => activeTags.some((tag) => item.tags.includes(tag)));

      let searchQuery = '';

      function renderFilters() {
        if (!filterContainer) return;
        filterContainer.innerHTML = '';
        const tags = ['ALL'].concat(allTags);
        const query = searchQuery.toLowerCase().trim();
        
        tags.forEach((tag) => {
          const isAll = tag === 'ALL';
          const tagLower = String(tag).toLowerCase();
          const matchesSearch = isAll || !query || tagLower.includes(query);
          
          if (!matchesSearch) return;
          
          const isActive = isAll ? activeTags.length === 0 : activeTags.includes(tag);
          const btn = document.createElement('button');
          btn.className = 'filter-chip ' + (isActive ? 'active' : '');
          btn.innerText = isAll ? 'ALL' : String(tag);
          btn.setAttribute('aria-pressed', isActive);
          btn.onclick = () => {
            if (isAll) {
              activeTags = [];
            } else {
              activeTags = activeTags.includes(tag)
                ? activeTags.filter((t) => t !== tag)
                : activeTags.concat([tag]);
            }
            activeIndex = -1;
            resetDetails();
            renderFilters();
            renderSelectedTagsPreview();
            updateFilterCount();
            renderGallery();
          };
          filterContainer.appendChild(btn);
        });
      }

      function renderSelectedTagsPreview() {
        if (!selectedTagsPreview) return;
        selectedTagsPreview.innerHTML = '';
        if (activeTags.length === 0) return;
        
        activeTags.forEach((tag) => {
          const chip = document.createElement('span');
          chip.className = 'selected-tag-preview';
          chip.innerHTML = `
            <span>${tag}</span>
            <span class="remove-tag" data-tag="${tag}">√ó</span>
          `;
          chip.querySelector('.remove-tag').onclick = (e) => {
            e.stopPropagation();
            activeTags = activeTags.filter((t) => t !== tag);
            activeIndex = -1;
            resetDetails();
            renderFilters();
            renderSelectedTagsPreview();
            updateFilterCount();
            renderGallery();
          };
          selectedTagsPreview.appendChild(chip);
        });
      }

      function updateFilterCount() {
        if (!filterCount) return;
        if (activeTags.length > 0) {
          filterCount.textContent = activeTags.length;
          filterCount.classList.add('active');
        } else {
          filterCount.classList.remove('active');
        }
      }

      function openFilterPanel() {
        if (filterPanel) {
          filterPanel.setAttribute('aria-hidden', 'false');
          document.body.style.overflow = 'hidden';
          requestAnimationFrame(() => {
            if (filterSearchInput) filterSearchInput.focus();
          });
        }
      }

      function closeFilterPanel() {
        if (filterPanel) {
          filterPanel.setAttribute('aria-hidden', 'true');
          document.body.style.overflow = '';
          searchQuery = '';
          if (filterSearchInput) filterSearchInput.value = '';
          renderFilters();
        }
      }

      // Filter panel event handlers
      if (filterToggle) {
        filterToggle.addEventListener('click', openFilterPanel);
      }
      if (filterPanelClose) {
        filterPanelClose.addEventListener('click', closeFilterPanel);
      }
      if (filterPanelBackdrop) {
        filterPanelBackdrop.addEventListener('click', closeFilterPanel);
      }
      if (filterSearchInput) {
        filterSearchInput.addEventListener('input', (e) => {
          searchQuery = e.target.value;
          renderFilters();
        });
        filterSearchInput.addEventListener('keydown', (e) => {
          if (e.key === 'Escape') {
            closeFilterPanel();
          }
        });
      }
      document.addEventListener('keydown', (e) => {
        if (e.key === 'Escape' && filterPanel?.getAttribute('aria-hidden') === 'false') {
          closeFilterPanel();
        }
      });

      function centerCard(el, smooth = true) {
        if (!container || !el) return;
        
        requestAnimationFrame(() => {
          const isActive = el.classList.contains('active');
          const openWidth = 450;
          
          // Get current scroll position and container dimensions
          const scrollLeft = container.scrollLeft;
          const containerRect = container.getBoundingClientRect();
          const elRect = el.getBoundingClientRect();
          
          // Calculate the card's position relative to the scroll container
          const cardLeftInScroll = scrollLeft + (elRect.left - containerRect.left);
          
          // If active, use the expanded width; otherwise use current width
          const finalWidth = isActive ? openWidth : elRect.width;
          
          // Calculate where the center of the card will be (or is)
          const cardCenter = cardLeftInScroll + (finalWidth / 2);
          
          // Calculate desired scroll to center the card
          const desired = cardCenter - (containerRect.width / 2);
          
          const maxScroll = Math.max(0, container.scrollWidth - containerRect.width);
          const target = Math.min(Math.max(0, desired), maxScroll);
          
          container.scrollTo({ left: target, behavior: smooth ? 'smooth' : 'auto' });
        });
      }

      function setActiveIndex(newIndex) {
        const filtered = getFilteredData();
        if (!filtered.length) return;
        const count = filtered.length;
        const normalized = ((newIndex % count) + count) % count;
        activeIndex = normalized;
        updateDetails(filtered[normalized]);
        centerActiveOnRender = true;
        renderGallery();
      }

      function centerGalleryToMiddle() {
        if (!container) return;
        const items = container.querySelectorAll('.vhs-item');
        if (items.length === 0) {
          container.classList.remove('centered');
          return;
        }
        container.classList.add('centered');
        
        // Always scroll to center the middle item
        requestAnimationFrame(() => {
          requestAnimationFrame(() => {
            const middleIndex = Math.floor(items.length / 2);
            const middleItem = items[middleIndex];
            if (middleItem) {
              // Calculate center position
              const containerRect = container.getBoundingClientRect();
              const itemRect = middleItem.getBoundingClientRect();
              const scrollLeft = container.scrollLeft;
              const itemLeftInScroll = scrollLeft + (itemRect.left - containerRect.left);
              const itemWidth = itemRect.width;
              const itemCenter = itemLeftInScroll + (itemWidth / 2);
              const targetScroll = itemCenter - (containerRect.width / 2);
              const maxScroll = Math.max(0, container.scrollWidth - container.clientWidth);
              const finalScroll = Math.min(Math.max(0, targetScroll), maxScroll);
              
              container.scrollTo({ left: finalScroll, behavior: 'auto' });
            }
          });
        });
      }

      function renderGallery() {
        container.innerHTML = '';
        const filtered = getFilteredData();

        if (activeIndex >= filtered.length) {
          activeIndex = -1;
          resetDetails();
        }

        filtered.forEach((item, index) => {
          const el = document.createElement('div');
          const isActive = index === activeIndex;
          el.className = 'vhs-item ' + (isActive ? 'active' : '');

          el.innerHTML =
          '<div class="vhs-spine-content">' +
            '<div class="vhs-code">' + item.code + '</div>' +
            '<div class="vhs-spine-text">' + item.title + '</div>' +
            '<div class="vhs-code">' + item.year + '</div>' +
            '<div class="vhs-play-icon" aria-hidden="true">‚ñ∂</div>' +
          '</div>' +
            '<div class="vhs-open-content">' +
            '<img src="' + item.image + '" class="vhs-img-bg" alt="Cover">' +
            '<div class="vhs-info-layer">' +
            '<h3 class="vhs-title">' + item.title + '</h3>' +
            '<p class="vhs-desc">' + item.desc + '</p>' +
            '<div class="vhs-tags">' +
            item.tags.map((t) => '<span class="vhs-tag">' + t + '</span>').join('') +
            '</div>' +
            '</div>' +
            '</div>';

          el.onclick = () => {
            if (activeIndex === index) {
              activeIndex = -1;
              resetDetails();
              centerActiveOnRender = false;
              renderGallery();
              // Re-center immediately after closing
              requestAnimationFrame(() => {
                centerGalleryToMiddle();
              });
            } else {
              activeIndex = index;
              updateDetails(item);
              centerActiveOnRender = true;
              renderGallery();
            }
          };

          container.appendChild(el);
        });

        if (centerActiveOnRender && activeIndex >= 0) {
          container.classList.remove('centered');
          container.classList.add('has-active');
          requestAnimationFrame(() => {
            const activeEl = container.querySelector('.vhs-item.active');
            if (activeEl) {
              // Center immediately based on final expanded position
              centerCard(activeEl, true);
            }
            centerActiveOnRender = false;
            finishGalleryLoading();
          });
        } else if (activeIndex === -1) {
          container.classList.remove('has-active');
          // Center gallery when no item is selected (whether filtered or not)
          finishGalleryLoading();
          // Use double RAF to ensure layout has settled before centering
          requestAnimationFrame(() => {
            requestAnimationFrame(() => {
              centerGalleryToMiddle();
            });
          });
        } else {
          container.classList.remove('centered');
          container.classList.add('has-active');
          finishGalleryLoading();
        }
      }

      function buildToc() {
        if (!detailToc) return;
        detailToc.innerHTML = '';
        const headings = detailContent.querySelectorAll('h2, h3, h4, h5');
        if (!headings.length) return;
        const list = document.createElement('ul');
        list.className = 'toc-list';
        headings.forEach((h) => {
          const id = h.id || h.textContent.trim().toLowerCase().replace(/[^a-z0-9]+/g, '-');
          if (!h.id) h.id = id || 'section';
          const li = document.createElement('li');
          li.className = 'toc-item level-' + h.tagName.toLowerCase();
          const link = document.createElement('a');
          link.href = '#' + h.id;
          link.textContent = h.textContent.trim();
          li.appendChild(link);
          list.appendChild(li);
        });
        detailToc.innerHTML = '<span class="toc-label">Contents</span>';
        detailToc.appendChild(list);
      }

      function updateDetails(item) {
        setDetailTitle(item.title);
        setDetailSummary(item.desc || 'No summary available.');
        setDetailBodyMessage('');
        const metaLine = [item.year, item.format].filter(Boolean).join(' // ');
        detailYear.innerText = metaLine || '--';
        detailToc.innerHTML = '';
        // Don't center here - let renderGallery handle it after transition
        detailTags.innerHTML = item.tags.map((t) => '<span class="detail-tag">' + t + '</span>').join('');
        detailActions.innerHTML = item.articleSlug
          ? '<a class="detail-link" href="/projects/' + encodeURIComponent(item.articleSlug) + '/">Open full article</a>'
          : '';
        const html = contentCache.get(item.slug) || storedContent.get(item.slug) || '';
        let cleaned = html ? stripHeaderAndSummary(html) : '';
        // Enhance markdown rendering
        cleaned = enhanceMarkdownRendering(cleaned);
        detailContent.innerHTML = cleaned || '<p>Unable to load this tape right now.</p>';
        buildToc();

        const section = document.querySelector('.details-section');
        if (section) {
          section.style.opacity = 0.5;
          setTimeout(() => {
            section.style.opacity = 1;
          }, 200);
        }
      }

      function resetDetails() {
        setDetailTitle('Select a Project Tape');
        setDetailSummary('Select a project tape to view its summary.');
        setDetailBodyMessage('Browse the archive above. Click a project tape to load details.');
        detailYear.innerText = '--';
        detailContent.innerHTML = '';
        detailTags.innerHTML = '';
        detailActions.innerHTML = '';
        detailToc.innerHTML = '';
      }

      document.getElementById('prevBtn').onclick = () => {
        const filtered = getFilteredData();
        if (!filtered.length) return;
        if (activeIndex === -1) {
          setActiveIndex(filtered.length - 1);
        } else {
          setActiveIndex(activeIndex - 1);
        }
      };
      document.getElementById('nextBtn').onclick = () => {
        const filtered = getFilteredData();
        if (!filtered.length) return;
        if (activeIndex === -1) {
          setActiveIndex(0);
        } else {
          setActiveIndex(activeIndex + 1);
        }
      };

      loadProjects().then(centerGalleryToMiddle);
      window.addEventListener('resize', () => {
        if (activeIndex === -1) {
          requestAnimationFrame(centerGalleryToMiddle);
        } else {
          const activeEl = container?.querySelector('.vhs-item.active');
          if (activeEl) {
            requestAnimationFrame(() => centerCard(activeEl));
          }
        }
      });
    </script>  </main> <script>
      const html = document.documentElement;
      const themes = ['light', 'dark'];
      (function initTheme() {
        let saved = localStorage.getItem('theme') || 'light';
        if (!themes.includes(saved)) saved = 'light';
        html.setAttribute('data-theme', saved);
        const next = themes[(themes.indexOf(saved) + 1) % themes.length];
        const btn = document.getElementById('themeToggle');
        if (btn) btn.innerText = next.toUpperCase();
      })();
      function toggleTheme() {
        const current = html.getAttribute('data-theme');
        const idx = themes.indexOf(current);
        const next = themes[(idx + 1) % themes.length];
        html.setAttribute('data-theme', next);
        const afterNext = themes[(idx + 2) % themes.length];
        const btn = document.getElementById('themeToggle');
        if (btn) btn.innerText = afterNext.toUpperCase();
        localStorage.setItem('theme', next);
      }
      const toggle = document.getElementById('themeToggle');
      if (toggle) toggle.addEventListener('click', toggleTheme);
    </script> </body> </html>